<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2019 年 2 月份总结]]></title>
    <url>%2F2019%2F02%2F28%2F20190228%2F</url>
    <content type="text"><![CDATA[今天是 2 月最后一天了，春节返工也快三周了，相信大家都已经完全渡过「节后综合症」阶段，全身心投入工作中了，在此做个月总结。 整体来说，我对这个月的工作和学习还是比较满意的，先说一下已完成和未完成的事情吧。 一、已完成1、第一周（2.11-2.17） 学习 Redis 的基础知识，并输出 4 篇博客（参见https://blog.csdn.net/lijing742180/article/details/87455550）。 关于 JVM、OOM 相关的知识学习了一部分。 整理纸质笔记；整理衣柜；周六早上跑步； 2、第二周（2.18-2.24） 继续学习完 JVM 内存模型、OOM 和 GC 机制，并输出 3 篇博客（参见https://blog.csdn.net/lijing742180/article/details/87857509）。 周末两天看书：《冥想》《我不惧怕成为这样强硬的姑娘》《保险入门》（还没来得及输出读书笔记） 3、第三周（2.25-3.3） 完善个人博客，添加了几个小功能，并推送了 42 篇文章。 整理了一部分收藏的电子笔记资料（但是还有好多啊。。。） 输出几本书的读书笔记。（=还未完成，计划这周末完成=） 二、未完成这个月初我定的计划里最重要的事情是「整理」（包括衣柜、书架、收藏夹等资料），但是并没有完成多少。 1、整理书架 这里的整理并不是仅仅摆放整齐，而是要对书籍「更新换代」，把之前买了很久的书赶紧看完，然后再去买新书，给书架来个大换血。 俗话说「买书如山倒，读书如抽丝」，如果不定时审视自己的书架，很容易陷入只买不读的情况，结果书架都被塞满了，但是真正读过的没几本。 2、整理收藏夹等资料 我们看到各种觉得好的文章，习惯性的随手收藏，过后却很少记得去看。长此以往，各种电子收藏夹里堆的东西越来越多，自己拥有一个庞大的知识宝库，但是自己真正会的知识却少得可怜。 你不妨去翻翻自己的微信或QQ等收藏夹里，去年甚至前年的资料有多少？你看了多少？今天还要继续塞多少？ 清空旧知，才能接受新知。 这也是为什么我会把整理收藏夹作为今年初的一件很重要的事情来对对待。 一篇篇认真看一下自己曾认为好的文章，然后取之精华，弃之糟粕，整理到已有的知识体系中，然后删除它。 这个过程比较花时间，而且以前随手屯的资料又太多，所以比预想的进行的慢，继续吧！ 3、英语 之前定的计划是每天坚持学英语，但是这个月只是隔三岔五的学了一下，下个月这方面要加强。]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>月总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Busuanzi网站统计失效问题]]></title>
    <url>%2F2019%2F02%2F27%2FBusuanzi%E7%BD%91%E7%AB%99%E7%BB%9F%E8%AE%A1%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在 Hexo 博客中，我使用的 Next 5.1 主题中默认集成了第三方统计服务 Busuanzi 来统计网站数据，但是实际并没有生效。 问题原因是由于 busuanzi(不蒜子) 的域名更新，导致了使用 Hexo Next 主题时统计数据失效。 不蒜子的域名由原来的 dn-lbstatics.qbox.me 更换为了 busuanzi.ibruce.info。 解决方法: 到 hexo 的 themes 文件夹下, 进入 \themes\next\layout_third-party\analytics 目录 打开 busuanzi-counter.swig 将 src=&quot;https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js&quot; 修改为 src=&quot;https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot; 然后使用 hexo g 、hexo d 命令重启服务器即可生效。]]></content>
      <categories>
        <category>个人博客</category>
      </categories>
      <tags>
        <tag>Busuanzi</tag>
        <tag>Busuanzi统计</tag>
        <tag>Busuanzi统计失效</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git操作本地仓库和远程仓库的常用命令]]></title>
    <url>%2F2019%2F02%2F27%2FGit%E6%93%8D%E4%BD%9C%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E5%92%8C%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93%E7%9A%84%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[总结使用 Git 过程中的一些基本的、常用的命令。 一、操作本地仓库 命令示例 解释 git config –list 查看已有的全部配置信息 git config user.name 查看某个指定的环境变量的信息 git config –global user.name “ivyli” 绑定用户名为 ivyli git config –global user.email “ivyli2019@126.com“ 绑定邮箱为 ivyli2019@126.com git init 在空目录下执行该命令，从而初始化当前目录为可管理的git仓库，生成隐藏的 .git 文件(不能乱动，否则仓库就不能用了) git add 1.txt 把本地编辑好的 1.txt 文件添加到暂存区 git add . 把当前目录下的所有文件都添加到暂存区 git status 随时查看仓库状态 git commit –m “add 1.txt” 提交文件到本地仓库，–m 添加注释信息.commit 文件之后再修改，需要重新 add、commit git rm 1.txt 删除版本库中的文件 1.txt（删除文件时最好用该命令，不要手动删除） git commit -m “del 1.txt” git rm 1.txt 之后还要 commit，才能真正删除 git diff 1.txt 查看 1.txt 文件修改了那些内容 git log 查看历史记录 对本地仓库的操作，主要就是 git add/rm/commit/status。 当文件 commit 到本地版本库之后，若再次修改文件，需要重新 add、commit，若是删除文件，需要重新 commit。 二、操作远程仓库我们可以 clone 远程仓库到本地，也可以把本地文件 push 到远程仓库。 但是在第一次操作远程仓库时，会报错 Permission denied(publickey)，这是因为没有添加 SSH 公钥。 1ssh-keygen -t rsa -C "ivyli2019@126.com" 执行上述命令，可以在本地生成 .ssh 文件，复制文件中的 id_rsa.pub 公钥内容到 git 或其它源码平台，即可添加 SSH 公钥。 命令示例 解释 git clone git://gitee.com:ivyli2019/test.git 从远程库中克隆项目到本地，是一个包含整个项目的版本库文件夹。该命令通常用于新用户 clone 项目，后面基本都是用 git pull。 git remote 查看远程库的别名（进入 clone 下来的文件夹中执行该命令，别名默认是 origin） git remote –v 查看远程库的别名和仓库地址。如返回：origin git@gitee.com:ivyli2019/test.git git push origin master 把本地 master 分支推送到别名为 origin 的远程库 git remote add mytest git://gitee.com:ivyli2019/mytest.git 添加/关联一个远程仓库，并起别名为 mytest，可自定义别名。 git remote remove mytest 删除远程库的 mytest 别名 git branch 查看当前所有的分支，默认只有 master 分支 git branch test 创建 test 分支 git branch –d test 删除 test 分支 git checkout test 从当前分支切换到 test 分支 git checkout –b dev 创建 dev 分支，并切换到 dev 分支上 git merge dev 在当前分支上合并 dev 分支]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>本地仓库</tag>
        <tag>远程仓库</tag>
        <tag>git命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Next 主题中添加本地搜索功能]]></title>
    <url>%2F2019%2F02%2F27%2FHexo%20Next%20%E4%B8%BB%E9%A2%98%E4%B8%AD%E6%B7%BB%E5%8A%A0%E6%9C%AC%E5%9C%B0%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[在 next 主题侧边列表有一个 搜索 菜单，但是点击之后页面会处于卡死状态，后台显示是 404，需要添加搜索插件才可以。 1、安装本地搜索插件 hexo-generator-search12# 安装插件，用于生成博客索引数据（在博客根目录下执行下列命令）：npm install hexo-generator-search --save 安装之后，会在站点目录的 public 文件夹下创建一个 search.xml 文件。 2、修改站点配置文件在站点配置文件 _config.yml 中添加如下内容：123456# Search search: path: ./public/search.xml field: post format: html limit: 10000 path：索引文件的路径，相对于站点根目录 field：搜索范围，默认是 post，还可以选择 page、all，设置成 all 表示搜索所有页面 limit：限制搜索的条目数 3、主题配置文件在主题配置文件 _config.yml 中找到如下内容：1234local_search: enable: true trigger: auto top_n_per_article: 1 确保 enable 设成 true。 top_n_per_article 字段表示在每篇文章中显示的搜索结果数量，设成 -1 会显示每篇文章的所有搜索结果数量。 然后，重新部署网站即可愉快的使用本地搜索功能了，效果参见本网站右侧的 搜索 菜单。]]></content>
      <categories>
        <category>个人博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next主题搜索</tag>
        <tag>next本地搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客使用LeanCloud统计页面访问次数]]></title>
    <url>%2F2019%2F02%2F27%2FHexo%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8LeanCloud%E7%BB%9F%E8%AE%A1%E9%A1%B5%E9%9D%A2%E8%AE%BF%E9%97%AE%E6%AC%A1%E6%95%B0%2F</url>
    <content type="text"><![CDATA[本文环境： Hexo + Next v5.1.4 在 Hexo 博客中，借助 LeanCloud 第三方服务来实现统计页数访问次数的功能。 1、配置 LeanCloud 进入官网 https://leancloud.cn/，进入右侧控制台并注册账号、验证邮箱； 创建应用：控制台 -&gt; 创建应用（开发版） 应用名称可以随意输入，后面还可以修改，我用的是 test； 创建 Class：点击刚创建的 test 应用，创建一个 Class 表用来保存我们的博客访问数据。 此处创建的 Class 名字必须为 Counter，用来保证与 NexT 主题的修改相兼容； ACL 权限选择 无限制，避免后续因为权限的问题导致次数统计显示不正常。 创建 Class 完成之后，新创建的 Counter 表会显示在左侧，这时再切换到 test 应用的 设置 - 应用 Key 界面： 把你的 AppID 和 AppKey 复制出来。 2、修改主题配置文件打开 NexT 主题的 _config.yml 文件，把刚才拿到的 AppID 和 AppKey 和填入下面相应位置：1234leancloud_visitors: enable: true # 这里要设置成 true app_id: joaeddf4hsqudUUwx4gIvGF6-gzGzoHsz app_key: E9UJsJpw1omCHuS22PdSpKoh 这时再使用 hexo g、hexo d 命令重新部署博客，就可以正常使用文章阅读量统计的功能了，如下图所示： 需要特别说明的是： 记录文章访问量的唯一标识符是文章的发布日期和文章的标题，因此要确保这两个数值组合的唯一性，如果你更改了这两个数值，会造成文章阅读数值的清零重计。 3、后台管理当以上部分配置完成之后，我们的博客页面第一次打开时，便会自动向服务器发送信息，在我们刚才创建的应用 test 的 Counter 表中创建一条数据。 其中 time 字段的数值表示某一篇文章的访问量。其他字段的具体作用可以查阅 LeanCloud 官方文档，最好不要随意修改。]]></content>
      <categories>
        <category>个人博客</category>
      </categories>
      <tags>
        <tag>hexo博客</tag>
        <tag>LeanCloud</tag>
        <tag>hexo博客统计访问次数</tag>
        <tag>LeanCloud统计访问次数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git pull 指定某一个文件或文件夹]]></title>
    <url>%2F2019%2F02%2F26%2Fgit%20pull%20%E6%8C%87%E5%AE%9A%E6%9F%90%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E6%88%96%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[1、要解决的问题默认情况下，git pull 操作会把远程仓库的所有最新数据更新到本地。 但是，如果你只想更新指定的某一个文件或文件夹，该怎么操作呢？ 2、git 只 pull 某一个文件/夹 设置 core.sparsecheckout为 true $ git config core.sparsecheckout true core.sparsecheckout用于控制是否允许设置pull指定文件/夹，true为允许。 此方法适用于 Git1.7.0 以后版本，之前的版本没有这个功能。 在.git/info/sparse-checkout文件中（如果没有则创建）添加指定的文件/夹 最后，拉取想要的分支即可实现checkout指定文件/夹。 $ git pull origin master]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>git pull</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nGrinder详细介绍及性能测试工具对比]]></title>
    <url>%2F2019%2F02%2F26%2F01_nGrinder%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[目前主流的性能测试工具，除了LR、JMeter之外，还有很多公司在用B/S架构的nGrinder 。最近公司搭建了一个基于nGrinder的二次开发平台，在此写一波nGrinder相关的文章。 在介绍nGrinder之前，有必要先说一下 The Grinder 抛砖引玉。 一、The Grinder1、The Grinder是一个基于Java的开源性能测试框架，通过多个agent负载机很方便的进行分布式测试。 2、主要特性： 可以测试任何java代码，包括各种常用的接口 如HTTP web servers, SOAP和REST web services，还有客户端服务器RMI、JMS、EJBs等，还支持自定义协议。 测试脚本使用python和Clojure语言 成熟的HTTP协议支持： 自动管理客户端连接和cookies，SSL代理； 支持录制脚本，能够记录并回放浏览器和网站之间的复杂交互。 包括console和agent端 3、不足 一次只能运行一个测试 没有测试历史记录 没有图形化的测试报告 二、nGrinder nGrinder是基于Grinder的开源的web性能测试平台，由韩国最大互联网公司NHN公司的开发团队进行了重新设计和完善。 特性：开源、易用、高可用、可扩展 1、nGrinder 在 Grinder 的基础上： 实现多测试并行 基于web的管理 实现cluster 内置svn，方便的脚本编辑、管理 支持Groovy脚本，相对于Jython，可以启动更多的虚拟用户 实现对目标服务器的监控 插件系统扩展 2、工作原理 由一个控制端controller和多个代理端agent组成，通过控制端(浏览器访问)建立测试场景，然后分发到代理端进行压力测试。 用户按照一定规范编写测试脚本，controller会将脚本以及需要的资源分发到agent，用jython执行。 在脚本执行的过程中收集运行情况、相应时间、测试目标服务器的运行情况等。并且保存这些数据生成测试报告，通过动态图和数据表的形式展示出来。用户可以方便的看到TPS、被测服务器的CPU和内存等情况。 三、LoadRunner JMeter 与 nGrinder对比1、Loadrunner 基于UI操作，容易上手。早期很流行，功能强大，但是太笨重，安装很麻烦。 不开源，扩展性不高，收费贵。往后的方向肯定是客户端工具逐步向平台化发展，所以已经慢慢被替代了。 2、JMeter 基于UI操作，容易上手，但是编程能力较弱（使用beanshell脚本语言）。 其次JMeter基于线程，模拟数千用户几乎不可能。 3、nGrinder 单节点可支持4000~6000并发、支持分布式、可监控被测服务器、可录制脚本、开源、平台化。 参数化功能较弱 对测试人员的代码要求较高 比较点 JMeter Ngrinder LoadRunner 实现语言 Java java/python java/VB/C/.NET 使用方式 C/S或Command B/S B/S 支持分布式 master/slave controller/agent master/slave 资源监控 monitor/plugin，如果二开，需要查找plugin的源码 monitor方式，有直接可用的源码 自带资源监控功能 社区活跃度 文档完善 有中文社区 网上资料和相关培训很多，购买正版还可以得到技术支持 是否需要编码 基本不需要 需要，Jython/Groovy 需要 脚本的维护 本地 内置SVN 本地 脚本录制 可使用BadBoy进行录制 可通过PTS插件进行录制 自带录制功能 可扩展性 可增加plugin，输出结果可以再加工 可增加plugin 通过扩展函数库实现 安装 简单，解压即可 简单，可以下载安装包或绿色包解压 安装包比较大，安装繁琐 nGrinder 安装配置及使用 见下篇。]]></content>
      <categories>
        <category>nGrinder</category>
      </categories>
      <tags>
        <tag>nGrinder</tag>
        <tag>性能测试工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beanshell Sampler 常用方法]]></title>
    <url>%2F2019%2F02%2F26%2FBeanshell%20Sampler%20%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一、Beanshell Sampler1、BeanshellBeanshell 是一种轻量级的 Java 脚本，纯 Java 编写的，能够动态的执行标准 java 语法及一些扩展脚本语法，类似于 js 和 perl。 2、内置变量Beanshell Sampler 中除了可以使用标准 java 语法之外，还有一些定义好的变量，可以直接使用。 SampleResult ResponseCode, ResponseMessage IsSuccess Label FileName ctx vars props log 下面我按使用频率，分别讲一下最常用的几种变量。 3、log 用于打印日志，最常用，也最简单； 打印在 jmeter.log 中，可以设置打印级别，可以打印字符串、变量等。 使用方法：123456789101112131415161、打印 info 形式的普通字符串日志：log.info(&quot;hello world&quot;); 输出 hello world2、拼接字符串和变量 (其中 token 是 jmeter 局部变量)：log.info(&quot;hello world&quot; + &quot;$&#123;token&#125;&quot;); 输出 hello world 和 token 变量的拼接结果3、打印自定义变量str = &quot;12345&quot;;log.info(str); 输出 123454、打印 error 形式的普通字符串日志：log.info(&quot;hihihi&quot;);log.error(&quot;aaaaa&quot;);两种输出的区别：2018-12-27 19:05:13,158 INFO o.a.j.u.BeanShellTestElement: hihihi2018-12-27 19:05:13,158 ERROR o.a.j.u.BeanShellTestElement: aaaaa print() 打印日志 在 beanshell 中还可以使用 print() 函数来打印日志，输出字符串等信息； print() 是在 cmd 控制台中输出信息，log() 默认是在 jmeter.log 中输出信息。 4、vars 用于存取 jmeter 局部变量，很常用，一定要掌握； 通常用于存取字符串内容，也可以存取对象； vars.get()12String mykey = vars.get(&quot;keyname&quot;); 获取变量名为 keyname 的值，并保存在 mykey 中。 vars.put()12345vars.put(&quot;keyname&quot;,&quot;value&quot;); 把变量 keyname(值为 value)保存到 jmeter 变量中。vars.putObject(&quot;OBJname&quot;,new Object()); 把一个对象 OBJname 保存到 jmeter 变量中 vars.remove()12vars.remove(&quot;keyname&quot;);从 jmeter 变量中删除 keyname。 5、props 用于存取 jmeter 全局的静态变量； 其中的 key 和 value 均是字符串形式；12345ymd = props.get(&quot;START.YMD&quot;);获取属性 START.YMD 的值（脚本启动日期）。props.put(&quot;PROP1&quot;,&quot;1234&quot;);把 1234 存入全局属性 PROP1 中。 6、ctx 当前线程的上下文信息； 使用举例：12345678910111213ctx.getCurrentSampler(); 获取当前 sampler 请求ctx.getPreviousSampler(); 获取前一个 sampler 请求ctx.getThreadNum(); 获取当前线程的序号，从 0 开始计数ctx.getThread(); 获取当前线程ctx.getThreadGroup(); 获取当前线程组ctx.getProperties(); 获取所有属性ctx.getVariables(); 获取当前线程的所有变量 7、SampleResult12SampleResult.setResponseData(data);自定义响应数据。]]></content>
      <categories>
        <category>jmeter</category>
      </categories>
      <tags>
        <tag>beanshell</tag>
        <tag>jmeter</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nGrinder脚本结构-groovy]]></title>
    <url>%2F2019%2F02%2F26%2F03_%E8%84%9A%E6%9C%AC%E7%BB%93%E6%9E%84-groovy%2F</url>
    <content type="text"><![CDATA[在前面的文章中，我们已经知道，nGrinder支持groovy和Jython脚本，今天学习一下ngrinder中的groovy脚本结构。 ngrinder中的groovy脚本结构类似 junit，同时在junit的基础之上封装了自己的注解，用来控制脚本的运行。 一、运行逻辑图如下： 此处只列出了groovy脚本的逻辑，jython脚本是类似的，在此不再单独介绍. 二、各注解的使用比较 注解 描述 应用范围 用例 @BeforeProcess 定义在进程被调用之前应执行的行为 static method 加载被线程共享的资源文件，定义 GTest 等 @AfterProcess 定义在进程被终止之前应执行的行为 static method 关闭资源文件 @BeforeThread 定义在每个线程被调用之前应执行的行为 member method 登录目标系统，建立线程内的一些值，例如，Cookie 处理 @AfterThread 定义在每个线程被终止之前应执行的行为 member method 退出系统 @Before 定义每个被 @Test 注解的方法被执行前应执行的行为 member method 对个被 @Test 注解的方法的共享逻辑、变量设置 @After 定义每个被 @Test 注解的方法被执行后应执行的行为 member method 很少使用 @Test 定义测试行为，被执行多次 member method 测试体 三、关注点在ngrinder中，通常使用单进程多线程就足够大部分测试了，所以： 我们最需要关注的就是 @Test ，这个是循环体； 其次是 @Before ，这里设置多个循环体的共享变量； 再其次是 @BeforeThread 和 @AfterThread ，用于设置每个线程执行前后的行为。 四、具体代码结构123456789101112131415161718192021222324252627282930313233343536373839@RunWith(GrinderRunner) // 每个测试类都要加这个注解class TestRunner &#123; @BeforeProcess // 在每个进程启动前执行 public static void beforeProcess() &#123; // 加载资源文件、初始化 GTest 等 &#125; @BeforeThread // 在每个线程执行前执行 public void beforeThread() &#123; // 登录、设置 cookie 之类 &#125; @Before // 在每个 @Test 注解的方法执行前执行 public void before() &#123; // 设置变量、多个 @Test 方法共用的逻辑等 &#125; @Test // 在测试结束前不断运行。各个 @Test 注解的方法异步执行。 public void foo() &#123; // ... &#125; @Test public void bar() &#123; // ... &#125; @After // 在每个 @Test 注解的方法执行后执行 public void after() &#123; // 很少用到 &#125; @AfterThread public void afterThread() &#123; // 登出之类 &#125; @AfterProcess // 在每个进程结束后执行 public static void afterProcess() &#123; // 关闭资源 &#125;]]></content>
      <categories>
        <category>nGrinder</category>
      </categories>
      <tags>
        <tag>nGrinder</tag>
        <tag>groovy</tag>
        <tag>ngrinder脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nGrinder在GET请求中添加参数]]></title>
    <url>%2F2019%2F02%2F26%2F05_%E5%9C%A8GET%E8%AF%B7%E6%B1%82%E4%B8%AD%E6%B7%BB%E5%8A%A0%E5%8F%82%E6%95%B0-groovy%2F</url>
    <content type="text"><![CDATA[https://github.com/naver/ngrinder/wiki/How-to-pass-a-parameter-to-the-script 在GET请求脚本中添加添加信息头、cookies和自定义参数，有两种方式： 一种是在UI界面添加后自动生成脚本 一种是直接在脚本中添加 一、通过UI界面添加通过 UI 设置：脚本 -&gt; 新建脚本 -&gt; 显示高级配置 生成代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@RunWith(GrinderRunner)@FixMethodOrder(MethodSorters.NAME_ASCENDING)class TestRunner &#123;truepublic static GTest testtruepublic static HTTPRequest requesttruepublic static NVPair[] headers = []truepublic static NVPair[] params = []truepublic static Cookie[] cookies = []true@BeforeProcesstruepublic static void beforeProcess() &#123;truetrueHTTPPluginControl.getConnectionDefaults().timeout = 6000truetruetest = new GTest(1, "www.baidu.com")truetruerequest = new HTTPRequest()truetruetruetrue// =========下面是我刚才添加的参数=========truetrue// Set header datastruetrueList&lt;NVPair&gt; headerList = new ArrayList&lt;NVPair&gt;()truetrueheaderList.add(new NVPair("Connection", "keep-alive"))truetrueheaderList.add(new NVPair("User-Agent", "Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0"))truetrueheaders = headerList.toArray()truetrue// Set param datastruetrueList&lt;NVPair&gt; paramList = new ArrayList&lt;NVPair&gt;()truetrueparamList.add(new NVPair("name", "jing"))truetrueparamList.add(new NVPair("age", "18"))truetrueparamList.add(new NVPair("sex", "beauty"))truetrueparams = paramList.toArray()truetrue// Set cookie datastruetrueList&lt;Cookie&gt; cookieList = new ArrayList&lt;Cookie&gt;()truetruecookieList.add(new Cookie("myToken", "xxxxxxxx", "www.baidu.com", "", new Date(32503647599000L), false))truetruecookies = cookieList.toArray()truetrue// =========上面是我刚才添加的参数=========truetruegrinder.logger.info("before process.");true&#125;true@BeforeThreadtruepublic void beforeThread() &#123;truetruetest.record(this, "test")truetruegrinder.statistics.delayReports=true;truetruegrinder.logger.info("before thread.");true&#125;true@Beforetruepublic void before() &#123;truetruerequest.setHeaders(headers)truetruecookies.each &#123; CookieModule.addCookie(it, HTTPPluginControl.getThreadHTTPClientContext()) &#125;truetruegrinder.logger.info("before thread. init headers and cookies");true&#125;true@Testtruepublic void test()&#123;truetrueHTTPResponse result = request.GET("https://www.baidu.com", params)truetrueassertThat(result.statusCode, is(200))truetrue// 这是我通过引导页手动添加的断言truetrueassertThat(result.getText(), containsString("jing"))true&#125;&#125; 可以看到这种方式是在@beforeProcess中添加heads 、params、cookies。 二、直接在脚本中添加（在此只演示添加 headers 和 params的方式，添加cookies是类似的，不再赘述） 根据在脚本中添加的位置不同，可以分为以下几种方式： 1、在 @BeforeProcess 注解的方法里添加 headers 和 params这种方法跟第一种方法的效果是一样的1234567891011// 添加headersList&lt;NVPair&gt; headerList = new ArrayList&lt;NVPair&gt;()headerList.add(new NVPair("Accept-Language", "en-US,zh-CN;"))// ...可以添加多个headerheaders = headerList.toArray()// 添加paramsList&lt;NVPair&gt; paramList = new ArrayList&lt;NVPair&gt;()paramList.add(new NVPair("accessToken", "xxxxxxxxx"))// ...可以添加多个paramparams = paramList.toArray() 2、直接在TestRunner类的静态变量中添加 headers 和 params在整个类最前面定义静态变量的地方，直接给变量赋值：123456789// 添加headerspublic static NVPair[] headers = [ new NVPair("Accept-Language", "en-US,zh-CN;")]// 添加paramspublic static NVPair[] params = [ new NVPair("accessToken", "xxxxxxxxxx")] 3、在 @Test 注解的方法中添加 headers 和 params在发送request请求的方法里添加参数：1234567 // HTTPResponse result = request.GET("https://www.baidu.com", params) // 添加headersHTTPResponse result = request1.GET("https://www.baidu.com", [new NVPair("Accept-Language", "en-US,zh-CN;")] as NVPair[]) // 添加params HTTPResponse result = request.GET("https://www.baidu.com", [new NVPair("accessToken", "xxxxxx")] as NVPair[]) 到底选择哪种方式，要根据具体的参数类型和业务场景来决定。 三、两种方式的比较 ?123456789101112131415161718 限制很多，只能传1个参数（保存到名为 param 的属性），值只能由1-50个数字字母、_、,、.、| 组成，不能有空格。// 获取 UI 传入的字符串def foo = System.getProperty("param")// 带默认值def foo = System.getProperty("param", "XXX")// 3.2.3+ 可以放开自动生成的脚本里 import static net.grinder.util.GrinderUtils.* 的注释/* GrinderUtils 类有以下静态方法：getParam()getParam(String)getParamInt()getParamLong()getParamFloat()getParamDouble()getParamBoolean()*/]]></content>
      <categories>
        <category>nGrinder</category>
      </categories>
      <tags>
        <tag>nGrinder</tag>
        <tag>nGrinder请求参数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nGrinder解析响应结果并断言]]></title>
    <url>%2F2019%2F02%2F26%2F08_%E8%A7%A3%E6%9E%90%E5%93%8D%E5%BA%94%E7%BB%93%E6%9E%9C%E5%B9%B6%E6%96%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[一、解析 JSONhttps://github.com/naver/ngrinder/wiki/How-to-parse-JSON 1、使用 JSONObject 解析并断言假设服务器返回以下内容，成功标志是 “responseCode”: “0000”：12345678910111213141516171819202122232425import com.alibaba.fastjson.JSONObject// ...@Testpublic void test1()&#123;truetry&#123;truetrue//发送请求truetrueHTTPResponse result = request.POST("http://xxxx/aa/bb/cc.html");truetrue//获取返回报文truetrueString respCode = JSONObject.parseObject(result.getText()).get("responseCode");truetrueif (respCode.equals("0000")) &#123;truetruetrueprintln "===返回==========成功"+result.getText();truetruetrueassertTrue("成功&lt;&lt;&lt;", respCode.equals("0000"))truetruetrueassertThat(result.responseCode, is(200));truetrue&#125;else &#123;truetruetruegrinder.logger.error("===失败=========="+result.getText())truetruetrueassertFalse("失败&gt;&gt;&gt;", !respCode.equals("0000"))truetrue&#125;true&#125; catch (Exception ex) &#123;truetrueassertFalse("失败&gt;&gt;&gt;"+ex,false)truetruegrinder.logger.error("===异常======"+ex)true&#125;&#125; 2、使用groovy的JsonSlurper解析并断言假设服务器返回以下内容，成功标志是 “resultCode”: 1：123456&#123; "data": &#123; "token": "9de6d5f2b62d4bb686de8033fd00bc65" &#125;, "resultCode": 1&#125; 解析方式：123456import groovy.json.JsonSlurper// ...def jsonData = new JsonSlurper().parseText(result.text)assertThat(jsonData.resultCode, is(1)) 二、使用 JUnit 的断言1、断言HTTP状态码和响应体123456def result = request.GET("http://www.google.com")// HTTP 状态码assertThat(result.statusCode, is(200))// 响应体assertThat(result.text, containsString("google")) 2、断言HTTP状态码，并进行逻辑判断123456789@Testpublic void testGoogle()&#123; HTTPResponse result = request.GET("http://www.google.com"); if (result.statusCode == 301 || result.statusCode == 302) &#123; grinder.logger.warn("Warning. The response may not be correct. The response code was &#123;&#125;.", result.statusCode); &#125; else &#123; assertThat(result.statusCode, is(200)); &#125;&#125;]]></content>
      <categories>
        <category>nGrinder</category>
      </categories>
      <tags>
        <tag>nGrinder</tag>
        <tag>ngrinder解析json</tag>
        <tag>ngrinder断言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nGrinder解析最基本的GET请求脚本]]></title>
    <url>%2F2019%2F02%2F26%2F04_%E8%A7%A3%E6%9E%90%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84GET%E8%AF%B7%E6%B1%82%E8%84%9A%E6%9C%AC-groovy%2F</url>
    <content type="text"><![CDATA[一、自动生成GET请求脚本1、配置 Create a script在ngrinder管理台主页，点击script–&gt;Create a script，并填写脚本名称和请求的url； 点击 Create 按钮，nGrinder会自动生成对应的脚本结构，如果没有参数需要设置的话，可以直接运行了。 二、详细解析GET请求脚本脚本说明ngrinder自动生成的脚本如下所示（groovy版本）： 解析见代码中的注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import static net.grinder.script.Grinder.grinderimport static org.junit.Assert.*import static org.hamcrest.Matchers.*import net.grinder.plugin.http.HTTPRequestimport net.grinder.plugin.http.HTTPPluginControlimport net.grinder.script.GTestimport net.grinder.script.Grinderimport net.grinder.scriptengine.groovy.junit.GrinderRunnerimport net.grinder.scriptengine.groovy.junit.annotation.BeforeProcessimport net.grinder.scriptengine.groovy.junit.annotation.BeforeThread// import static net.grinder.util.GrinderUtils.* // You can use this if you're using nGrinder after 3.2.3import org.junit.Beforeimport org.junit.BeforeClassimport org.junit.Testimport org.junit.runner.RunWithimport org.junit.FixMethodOrderimport org.junit.runners.MethodSortersimport java.util.Dateimport java.util.Listimport java.util.ArrayListimport HTTPClient.Cookieimport HTTPClient.CookieModuleimport HTTPClient.HTTPResponseimport HTTPClient.NVPair/** * A simple example using the HTTP plugin that shows the retrieval of a * single page via HTTP. * * This script is automatically generated by ngrinder. * * @author admin */@RunWith(GrinderRunner)@FixMethodOrder(MethodSorters.NAME_ASCENDING)class TestRunner &#123;truepublic static GTest testtrue// 定义 HTTPRequest 静态变量 request，用于发送 HTTP 请求truepublic static HTTPRequest request true// 定义 NVPair 数组 headers ，用于存放通用的请求头数据truepublic static NVPair[] headers = []true// 定义 NVPair 数组 params ，用于存放请求参数数据truepublic static NVPair[] params = []true// 定义 Cookie 数组 cookies ，用于存放通用的 cookie 数据truepublic static Cookie[] cookies = []true@BeforeProcesstruepublic static void beforeProcess() &#123;truetrue// 设置请求响应超时时间（ms），超过则抛出异常truetrueHTTPPluginControl.getConnectionDefaults().timeout = 6000truetruetruetrue// 创建GTest对象，第一个参数1代表有多个请求/事务时的执行顺序IDtruetrue// 第二个参数是请求/事务的名称，会显示在summary结果中truetrue// 有多个请求/事务时，要创建多个GTest对象truetruetest = new GTest(1, "www.baidu.com") truetrue// 创建 HTTPRequest 对象，用于发起 HTTP 请求truetruerequest = new HTTPRequest() truetruegrinder.logger.info("before process.");true&#125;true@BeforeThreadtruepublic void beforeThread() &#123;truetrue// 注册事件，启动test，第二个参数要与@Test注解的方法名保持一致truetrue// 有多个请求/事务时，要注册多个事件truetruetest.record(this, "test")truetrue// 配置延迟报告统计结果truetruegrinder.statistics.delayReports=true;truetruegrinder.logger.info("before thread.");true&#125;true@Beforetruepublic void before() &#123;truetrue// 在这里可以添加headers属性和cookiestruetruerequest.setHeaders(headers)truetrue// 设置本次请求的 cookiestruetruecookies.each &#123; CookieModule.addCookie(it, HTTPPluginControl.getThreadHTTPClientContext()) &#125;truetruegrinder.logger.info("before thread. init headers and cookies");true&#125;true@Testtruepublic void test()&#123;truetrue// 发送GET请求truetrueHTTPResponse result = request.GET("https://www.baidu.com", params)truetrue// 断言HTTP请求状态码truetrueassertThat(result.statusCode, is(200))true&#125;&#125; GTest GTest是对测试记录进行统计的单元; 使用 GTest 的构造方法 GTest(int number, String description) 创建，在脚本内每个GTest对象都使用唯一的编号定义。 如果创建了多个编号一样的对象，最后只会选用第一个。 test.record()在@BeforeThread注解下会执行 test.record(this, &quot;test&quot;) record(Object target, String methodName) 这里使用 GTest的record方法给 GTest 配置需要进行统计的方法； target 指脚本对象，这里是this； methodName 是需要统计的方法名，通常都是被 @Test 注释的方法。如果未配置，方法会正常执行，但是没有统计结果数据； 每一个被 @Test 注释的方法都是一个整体事务，在运行测试时，即便里面有 多次 HTTP 请求也只做一次统计！！ Cookies可以通过 Cookie(String name, String value, String domain, String path, Date expires, boolean secure) 构造 cookie 对象，然后存放到相应的数组中，传递到请求中。]]></content>
      <categories>
        <category>nGrinder</category>
      </categories>
      <tags>
        <tag>nGrinder</tag>
        <tag>ngrinder脚本解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA 中的版本控制机制]]></title>
    <url>%2F2019%2F02%2F26%2FIDEA%20%E4%B8%AD%E7%9A%84%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[一、版本控制的分类1、版本控制 版本控制是指对软件开发过程中各种程序代码、配置文件及说明文档等文件变更的管理。 版本控制的内容主要包括：检入检出控制、分支和合并、历史记录。 2、集中式版本控制系统（CVCS）典型代表是 SVN，有如下特点： 管理方便，逻辑明确，操作简单，上手快 使用集中式服务器，安全易管理 对服务器性能要求高，数据库容量经常暴增，体量大 必须联网！如果不能连接到服务器上，就不能提交，还原，对比等等 分支管控不灵活 还有一个风险，就是如果源码库出现问题，导致项目代码丢失，那么大家手里的都是部分代码，就算勉强合并到一起，也不能保证项目源码的准确性。 3、分布式版本控制系统（DVCS）分布式相比于集中式的最大区别在于开发者可以提交到本地，每个开发者通过克隆（git clone），在本地机器上拷贝一个完整的Git仓库。 典型代表是 Git，有如下特点： 适合分布式开发，每一个个体都可以作为服务器。每一次Clone就是从服务器上pull到了所有的内容，包括版本信息 公共服务器压力和数据量都不会太大 速度快、灵活，分支之间可以任意切换 任意两个开发者之间可以很容易的解决冲突，并且单机上就可以进行分支合并 可以离线工作，不影响本地代码编写，等有网络连接以后可以再上传代码，并且可以在本地根据不同的需要新建自己的分支。 二、IDEA 中的版本控制机制1、Version Control File -&gt; Settings -&gt; Version Control ，这里是 IDEA 自带的用于支持主流版本控制软件的插件，如 git 、gitHub 、svn 、cvs等。 仅有插件并不能在 IDEA 中直接使用版本控制，还需要下载相应的版本控制软件才行。 2、Plugins File -&gt; Settings -&gt; Plugins ，这里是 IDEA 下载和管理插件的地方，在 Version Control 中展示的插件就是默认在这里已经下载了的。 三、IDEA 中配置版本控制软件1、SVN 先安装 SVN 客户端，或者是图形化工具，windows 推荐用 TortoiseSVN。 File -&gt; Settings -&gt; Version Control -&gt; Subverion，选择自己的 SVN 安装路径，否则 IDEA 可能无法正常识别SVN。 Clear Auth Cache，当使用过程中出现无法正常 checkout 等问题时，可以尝试点击这里清除缓存。 2、Git 先安装 Git 客户端，windows 下推荐用 TortoiseGit。 File -&gt; Settings -&gt; Version Control -&gt; Git，选择自己的 Git 安装路径，否则 IDEA 可能无法正常识别 Git。 3、GitHub 先注册 GitHub 账号 File -&gt; Settings -&gt; Version Control -&gt; GitHub -&gt; Add account，输入用户名和密码登录 GitHub，并点击 Test 测试连接是否成功。 四、代码检出和上传1、检出代码VCS -&gt; Checkout from Version Control 选择对应的版本控制系统，如 GitHub、SVN、Git 等，进一步从中检出项目。 以 SVN 为例： 先在本地创建一个空文件夹，右键 svn -&gt; checkout 所有代码； 在 IDEA 中 Import Module 导入； VCS -&gt; Checkout from Version Control -&gt; Subversion，输入 svn 地址，checkout 到工作空间目录。 2、上传代码VCS -&gt; Import into Version Control ，选择对应的版本控制系统，并进一步上传代码到版本控制系统中。 3、配置忽略文件File -&gt; Settings -&gt; Version Control -&gt; Ignored Files 在这里通过 + -设置是否把文件或目录加入到版本控制中。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA使用手册-02]]></title>
    <url>%2F2019%2F02%2F26%2FIntelliJ%20IDEA%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C-01%2F</url>
    <content type="text"><![CDATA[本文内容基于ideaIC-2018.2.6版本 一、添加/修改代码模板代码模板是用于自动生成某种格式的代码，节省代码编写的时间。 1.1 添加文件头部的注释模板在ideaIC-2018.2.6版本中，默认是没有文件头部的注释模板的，需要自己添加。 Editor &gt; File and Code Templates -&gt; Includes -&gt; File Header 在右侧输入注释模板内容，一般使用如下格式： 123/** * Created by $&#123;USER&#125; on $&#123;DATE&#125;. */ 其中 ${USER} 取的是主机名；${DATE} 是文件被创建时的日期。 保存模板后，新建一个类，就会发现 IDEA 在类上方自动帮我们创建了如上注释。 1.2 修改文件头部的注释模板如果你的 IDEA 中已经有注释模板了，想要修改内容或格式的话，方法类似。 还是定位到 File Header ，修改模板内容后保存即可。 二、缓存和索引2.1 缓存和索引的作用 IntelliJ IDEA 的缓存和索引主要是用来加快文件查询的速度，从而提高各种查找、代码提示等操作的速度。 2.2 创建/清除索引 首次创建或打开新项目时，IntelliJ IDEA 都会自动创建项目索引，可以在界面下方的状态栏中看到提示 Scanning files to index。 创建索引的耗时与项目的文件数量成正比，因此，在打开大型项目时，会发现IntelliJ IDEA比较卡，此时最好不要做任何操作，静待 IDEA 忙完了再说，不然会更卡。 2.3 清除/重建索引 在遇到一些突发情况时（如突然断电、蓝屏引起的强制关机等等），可能会造成缓存和索引的损坏，这种情况下重启 IDEA 后，会出现一些莫名其妙的问题，这时需要清除被损坏的缓存和索引文件。 File &gt; Invalidate Caches / Restart 打开清理缓存和索引的对话框一般选择第一项 Invalidate and Restart 这种清除方式的本质结果是删除了本地保存的 IDEA 的缓存文件和索引文件，一般是位于目录 C:\Users\当前系统的用户名\.IdeaIC版本号\system\caches、index、LocalHistory 。 所以如果因为突发情况导致项目都打不开的时候，可以直接把本地的 system 目录备份后删除，再重启后 IDEA 会重新创建新的缓存和索引文件。 三、编译方式 在 Eclipse 中是实时自动编译的，但是 IDEA 默认情况下需要手动点击编译按钮。 3.1 IDEA 四种编译方式在主菜单 Build 下有四种编译方式： Build Project，编译项目 对选定的 Project 进行编译，但只编译修改过的文件，没有修改过的文件不会进行编译； Build Module，编译模块 对选定的 Module 进行编译，但只编译修改过的文件，没有修改过的文件不会进行编译； Recomplie，重新编译类文件 对选定的Java 类文件进行强制性编译，不管目标是否被修改过； Rebuild Project，重新编译项目 对选定的 Project 进行强制性编译，不管目标是否被修改过（编译时间较长）； 3.2 IDEA 设置实时自动编译进入 File -&gt; Settings -&gt; Build、Execution、Deployment &gt; Complie 界面： Build project automatically：设置 IntelliJ IDEA 进行自动编译，但是会比较耗内存，所以不建议开启。 Build process heap size ：设置编译进程的堆内存大小，默认是700M，如果设置了自动编译可能会出现 OutOfMemoryError报错，此时可以适当增大该值的大小。 3.3 设置编译排除文件IntelliJ IDEA 在编译项目的时候，需要所有可编译文件全部编译通过，才能正常运行。当在开发过程中，某个文件暂时无法编译通过，但是又想运行其它文件时，可以它加到排除编译列表中。 具体方法为： 进入上面的 `Compile -&gt; Excludes `界面，点击右侧的+和-，即可添加或删减目录（或文件）进行编译排除 四、控制台输出中文乱码问题 进入 IntelliJ IDEA 安装目录的 bin 目录下，打开 idea.vmoptions文件，在尾部追加一行： -Dfile.encoding=UTF-8 打开 IDEA，进入 Run -&gt; Edit Configurations 界面，在 VM options 中填写同样内容： -Dfile.encoding=UTF-8 五、添加 jar 包File -&gt; Project Structure -&gt; Module -&gt; Dependencies -&gt; +JARs or directories 六、 Debug 菜单 以上图为例，上面从 Console 开始，往后图标依次为： Show Execution Point：显示执行断点（Alt + F10） Step Over ：跳到下一步 （F6） Step Into：进入代码或者方法内部（F5） Force Step Into ：强制进入代码或者方法内部（Alt + Shift + F7） Step Out：跳到下一个断点或者跳出方法（F7） Drop Frame：放弃当前 debug，重新执行 debug Run to Cursor：运行到光标处（Ctrl + R） 再看左边的一列图标，上从上向下依次为： Rerun &#39;xxxx&#39;：重新运行当前类（Ctrl + F11） Resume Program：从 debug 模式中恢复程序，执行到底（F8） Pause Program ：中止运行 Stop &#39;xxxx&#39;：停止当前类（Ctrl + F2） View Breakpoints：显示所有断点（Ctrl + Shift + F8） 七、代码回退7.1 使用场景在开发过程中，当删除了部分代码后想要恢复回去，可以通过多种方式回退回去，而不用担心要重新写啦！ 7.2 使用 Local History 回退代码 选中类文件右键，或直接在编辑区右键，选择 Local History -&gt; Show History 在弹出界面中会列出历史版本，可查看各版本的变更信息，选中要回退的版本，右键 -&gt; Revert即可 此方法更适合回退某个文件的情况，如果是涉及多个文件、甚至整个模块或项目要进行回退，就要用别的办法了 7.3 使用 svn 回退代码 如果项目是通过Subversion也就是SVN检出的，那么可以使用 SVN 来回退 在项目名称上点击右键 -&gt; Subversion -&gt; Revert，即可进行代码回退 需要注意一点：这种方法是直接将代码恢复至从SVN检出时的状态，需谨慎使用 7.4 使用 git 回退代码==todo==]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>IntelliJ IDEA</tag>
        <tag>IDEA四种编译方式</tag>
        <tag>IDEA中文乱码</tag>
        <tag>IDEA代码回退</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven学习03-安装配置和maven仓库]]></title>
    <url>%2F2019%2F02%2F26%2FMaven%E5%AD%A6%E4%B9%A003-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%92%8Cmaven%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[一、安装及配置1、下载 到官网下载需要的版本： http://maven.apache.org/download.cgi，直接解压到本地 注意：安装maven之前，必须先确保你的机器中已经安装了对应版本的JDK 对象 要求 JDK Maven 3.3 要求 JDK 1.7 或以上Maven 3.2 要求 JDK 1.6 或以上Maven 3.0/3.1 要求 JDK 1.5 或以上 磁盘 Maven 自身安装需要大约 10 MB 空间。除此之外，额外的磁盘空间将用于你的本地 Maven 仓库。你本地仓库的大小取决于使用情况，但预期至少 500 MB 2、配置环境变量 添加系统环境变量MAVEN_HOME，并加在Path中 在cmd输入mvn –-version，如果出现maven的版本信息，说明配置成功 3、Maven配置文件settings.xmlMaven有两个配置文件settings.xml。 这两个配置文件里的设置，对所有的pom文件都是有效的。 两个配置文件路径分别为： Maven安装目录中：$M2_HOME/conf/settings.xml 用户主目录中：${user.home}/.m2/settings.xml 两个配置文件都是可选的。==如果两个文件都存在，则用户目录下的配置会覆盖Maven安装目录中的配置。== 4、修改本地仓库的路径从中央仓库下载的jar包，都会统一存放到本地仓库中。 默认的本地仓库地址是 ${user.home}/.m2。通常需要修改成自定义的位置。 打开maven安装目录，打开conf目录下的setting.xml文件，修改其中的 &lt;localRepository&gt;节点，设置成自己定义的目录即可。 二、Maven 仓库在 Maven 中，仓库就是一个位置（place），例如目录，用来存储所有的工程 jar 文件、library jar 文件、插件或任何其他的工程指定的文件。 1、Maven 仓库有三种类型 本地（local） 中央（central） 远程（remote） 2、本地仓库 Maven 本地仓库是本地机器上的一个文件夹。它在第一次运行任何 maven 命令的时候创建。 当运行一次 Maven 构建后，Maven 将从中央仓库和远程仓库中下载所有依赖的 jar 文件到本地仓库路径中。后面再次构建时直接引用本地的依赖文件 ，避免了每次构建时都引用存放在远程机器上的依赖文件。 2.1 修改本地默认仓库路径 Maven 本地仓库默认在 ${user.home}/.m2/repository %MAVEN_HOME%\conf\settings.xml文件中修改&lt;localRepository&gt;节点内容 123456&lt;!-- localRepository | The path to the local repository maven will use to store artifacts. | | Default: $&#123;user.home&#125;/.m2/repository&lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt;--&gt; 默认 &lt;localRepository&gt;节点是被注释的，需要先去掉注释，然后把其中的/path/to/local/repo替换成自己指定的路径即可。 3、中央仓库3.1 中央仓库概念 Maven 中央仓库是由 Maven 社区提供的仓库，其中包含了大量常用的库。 它由 Maven 社区管理，不需要配置。 需要通过网络才能访问。 3.2 访问中央仓库maven 社区提供了一个 URL：http://search.maven.org/#browse。 通过这个 URL 浏览中央仓库的内容，开发人员可以在中央仓库中搜索所有可以获取的代码库。 4、远程仓库4.1 远程仓库的概念如果 Maven 在中央仓库中也找不到依赖的库文件，它会停止构建过程并输出错误信息到控制台。 为避免这种情况，Maven 提供了远程仓库的概念，它是开发人员自己定制的仓库，包含了所需要的代码库或者其他工程中用到的 jar 文件。 4.2 定义远程仓库 在 pom.xml 中增加 &lt;repository&gt;节点，在其中定义远程仓库的id和url。 然后在 pom.xml 中增加&lt;dependency&gt;节点，在其中声明所依赖的文件（在中央仓库中获取不到的）。 类似下面这样：1234567891011121314151617181920212223242526&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.companyname.projectgroup&lt;/groupId&gt; &lt;artifactId&gt;project&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- 声明依赖文件 --&gt; &lt;groupId&gt;com.companyname.common-lib&lt;/groupId&gt; &lt;artifactId&gt;common-lib&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependencies&gt; &lt;repositories&gt; &lt;repository&gt; &lt;!-- 定义远程仓库 --&gt; &lt;id&gt;companyname.lib1&lt;/id&gt; &lt;url&gt;http://download.companyname.org/maven2/lib1&lt;/url&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;companyname.lib2&lt;/id&gt; &lt;url&gt;http://download.companyname.org/maven2/lib2&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/project&gt; 5、Maven 依赖搜索顺序当我们执行 Maven 构建命令时，Maven 开始按照以下顺序查找依赖的库： 本地仓库local -&gt; 中央仓库central -&gt; 远程仓库remote 详细查找顺序： 1、搜索本地仓库，如果找不到，继续第 2 步，如果找到了则执行其他操作。 2、搜索中央仓库，如果找到了则下载到本地仓库中备用； 如果找不到，并且有一个或多个远程仓库已经设置，则执行第 3 步；如果远程仓库没有被设置，则执行第 4 步报错。 3、在一个或多个远程仓库中搜索依赖的文件，如果找到则下载到本地仓库备用，否则执行第 4 步报错。 4、Maven 将简单的停滞处理并抛出错误（无法找到依赖的文件）。]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>maven安装配置</tag>
        <tag>maven仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven学习04-构建生命周期]]></title>
    <url>%2F2019%2F02%2F26%2FMaven%E5%AD%A6%E4%B9%A004-%E6%9E%84%E5%BB%BA%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[构建生命周期是指为一个工程进行项目构建和发布的过程，它是 Maven 中的一个核心概念。 1、标准生命周期Maven中内置了三个标准的构建生命周期： default（或build）：处理工程的部署 clean：处理工程的清理 site：负责创建工程的站点文档。 这三个构建生命周期都是由一系列不同的构建阶段组成，每一个构建阶段代表了生命周期的一个阶段。 2、default 生命周期的阶段一个典型的 Maven default（build）生命周期主要由以下几个阶段的序列组成（此处并完全列出）： 阶段 描述 验证 validate 验证项目是否正确且所有必须信息是可用的 编译 compile 源代码编译在此阶段完成 测试 Test 使用适当的单元测试框架（例如JUnit）运行测试。 包装 package 创建JAR/WAR包如在 pom.xml 中定义提及的包 检查 verify 对集成测试的结果进行检查，以保证质量达标 安装 install 安装打包的项目到本地仓库，以供其他项目使用 部署 deploy 拷贝最终的工程包到远程仓库中，以共享给其他开发人员和工程 使用默认的生命周期时，Maven将首先验证项目，然后将编译源代码，运行单元测试，再打包二进制文件（例如：jar），然后再对包文件进行集成测试（如果需要的话），再校验包文件，并将已经校验的包文件安装到本地仓库，然后在指定的环境中部署包。 3、生命周期阶段的执行顺序 各生命周期的阶段会被顺序地执行（包括那些这里没有展示的其他生命周期阶段）。 而且在调用一个生命周期阶段时，maven 不仅执行指定的构建阶段，也会执行指定构建阶段之前的每一个阶段 比如，在默认生命周期中，只需要调用最后一个deploy生命阶段，即可执行前面所有阶段：1234567891011121314mvn deploy // 会先执行前面的所有阶段mvn install // 会先执行前面的 validate ... verify 等阶段- 同样的命令可以用在多模块的情况下（即包含一个或多个子项目的工程）：mvn clean install// 会遍历所有的子项目，并且运行clean命令，然后运行install命令（包含所有之前步骤的命令） - 构建命令中也可以加入插件目标* 一个插件目标代表一个特定的任务（比构建阶段更为精细）。这些目标的执行顺序取决于调用目标和构建阶段的顺序。例如下面的命令：mvn clean dependency:copy-dependencies package// 其中clean 和 pakage 是构建阶段，dependency:copy-dependencies 是目标。// 执行顺序是` clean 阶段 -&gt; dependency:copy-dependencies 目标 -&gt; package 阶段 ` 4、Clean 生命周期clean 阶段用于清除上一次编译之后在target包下生成的字节码文件。 阶段 描述 pre-clean 执行一些清理前需要完成的工作 clean 清理上一次构建生成的文件 post-clean 执行一些清理后需要完成的工作 5、Site生命周期 阶段 描述 pre-site 执行一些在生成站点之前需要完成的工作 site 生成项目的站点文档 post-site 执行一些在生成站点之后需要完成的工作 site-deploy 将生成的站点文件发布到远程服务器上]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>maven生命周期</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JMeter源码导入IntelliJ IDEA]]></title>
    <url>%2F2019%2F02%2F26%2FJMeter%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5IntelliJ%20IDEA%2F</url>
    <content type="text"><![CDATA[之前文章中讲了 idea 导入 maven 项目，但是 jmeter 源码是 eclipse 项目结构，而且有些地方要进行特殊配置，所以单独记录一下。 使用环境： Win 7 + JMeter 5.0 + IntelliJ IDEA 2018.2.6 1、下载并解压 jmeter 源码 源码下载地址: http://jmeter.apache.org/download_jmeter.cgi，选择 Source 下的 zip 格式下载到本地； 解压到本地目录，如我的目录是 D:\software\apache-jmeter-5.0； 2、修改配置（重要！）这一步必须要进行，不然无法导入！ 进入解压后的目录，会看到两个文件：eclipse.classpath和eclipse.projecte，分别修改为 .classpath 和 .projecte ； 在 windows 下不能直接修改，要使用 cmd 命令行； 打开 cmd 命令行窗口，进入解压的源码目录下，执行： ren .eclipse.classpath .classpath ren .eclipse.project .project 3、导入 IDEA打开 IDEA，导入源码。 File -&gt; New -&gt; Project from Existing Sources ，选择源码目录； 选择按 eclipse 项目导入，如下所示： 其它全部按默认，一直 Next 即可。 4、Ant 下载依赖 jar 包 在窗口右侧 Ant Build 中，点击 + ，选择源码目录下的 build.xml，会把所有相关信息展示在右侧列表中； 双击列表中的 download_jars ,会自动下载所有缺失 jar 包，到 jmeter 源码目录的 lib 目录下； 5、更新项目中的依赖 jar 包在首次导入项目时，会自动在 dependency 下添加依赖 jar 包，但都是缺失状态，当我们用 Ant 下载好 jar 包后，IDEA 并不会自动更新，必须要手动更新。 在项目上右键打开 Open Module Settings,在项目 src 下点击 protocol 文件夹，再点击上方 Sources 按钮，点击 Apply。 点击 Dependencies，删除所有报错的 jar 包； 重新添加新下载的 jar 包：右侧 + ，选择 JARs or directories，依次选择源码目录下的 lib 目录和 lib 下的几个目录，最后 Apply ： 6、Ant install重新添加 jar 包后，必须执行 Ant install。 7、设置运行的 VM optionsJMeter 的启动类是 NewDriver，可以先找到这个类，尝试运行一下，肯定会报错找不到路径。 因为 jmeter 启动类中默认是去找的 parent 目录，所以报找不到路径，需要手动配置一下 jmeter 运行时的 home 路径，在 VM options 中配置。 在 VM options 填入 -Djmeter.home=D:\myWork\apache-jmeter-5.0，如下所示： 此时，再次运行 NewDriver，就可以正常启动 jmeter 界面了！！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jmeter</tag>
        <tag>IntelliJ IDEA</tag>
        <tag>jmeter源码导入IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven学习05-目录结构和依赖]]></title>
    <url>%2F2019%2F02%2F26%2FMaven%E5%AD%A6%E4%B9%A005-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E5%92%8C%E4%BE%9D%E8%B5%96%2F</url>
    <content type="text"><![CDATA[一、Maven目录结构Maven有一个标准的目录结构。如果在项目中遵循Maven的目录结构，就无需在pom文件中指定源代码、测试代码等目录。 1、常用的重要目录 src main java resources webapp test java resources target 2、各目录说明 目录 存放内容 src 源代码和测试代码的根目录 main 应用的源代码目录 test 测试代码的目录 java目录 main和test下的java目录，分别表示应用的java源代码和测试代码 resources 包含项目的资源文件，比如应用的国际化配置的属性文件等 webapp 如果是一个web项目，则webapp目录为web项目的根目录，其中包含如WEB-INF等子目录 target 是由Maven创建的目录，其中包含编译后的类文件、jar文件等。==当执行maven的clean目标后，target目录会被清空。== 二、依赖管理Maven内嵌有依赖管理的功能，可以非常方便的下载和管理项目依赖的外部jar包。 只需要在pom文件里指定依赖jar包的名称、版本号，Maven就会自动下载并放到本地仓库中（包括这些jar包依赖的其它库）。 1、如何设置项目依赖？在pom文件的&lt;dependencies&gt;属性中指定项目依赖。 一个&lt;dependency&gt;节点对应一个依赖，可以指定多个。 具体示例如下：1234567891011121314151617181920212223242526272829&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.jenkov.crawler&lt;/groupId&gt; &lt;artifactId&gt;java-web-crawler&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.jsoup&lt;/groupId&gt; &lt;artifactId&gt;jsoup&lt;/artifactId&gt; &lt;version&gt;1.7.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;/build&gt;&lt;/project&gt; 在上面的示例中，dependencies属性下有两个dependency子属性，每一个dependency属性描述了一个外部依赖。 每一个依赖由groupId, artifactId和version来描述。 上面的示例表明，项目的依赖为 org.jsoup组织下的1.7.1版本的jsoup，以及junit组织下的4.8.1版本的junit。 当Maven执行该pom文件时，将从Maven的中央仓库里下载这两个jar包并放到Maven的本地仓库。如果本地仓库中已经有了这两个依赖，Maven就不会去下载了。只有本地仓库中没有的依赖才会被下载。 若指定的依赖在Maven的中央仓库里没找到，可以手动下载，然后放到Maven的本地仓库。 下载的依赖必须放到与groupId、 artifactId和version匹配的子目录中。 上面示例中的两个依赖将会被放到以下子目录中： MAVEN_REPOSITORY_ROOT/junit/junit/4.8.1MAVEN_REPOSITORY_ROOT/org/jsoup/jsoup/1.7.1 三、快照依赖快照依赖指的是那些还在开发中的依赖（jar包）。 与其经常地更新版本号来获取最新版本，不如直接依赖项目的快照版本。 快照版本的每一个build版本都会被下载到本地仓库，即使该快照版本已经在本地仓库了。 总是下载快照依赖可以确保本地仓库中的每一个build版本都是最新的。 1、如何设置快照依赖？在pom文件的最开头（设置groupId和artifactId的地方），在版本号后追加-SNAPSHOT，则告诉Maven你的项目是一个快照版本。 如： &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; 在配置依赖时，在版本号后追加-SNAPSHOT表明依赖的是一个快照版本。 如：12345&lt;dependency&gt; &lt;groupId&gt;com.jenkov&lt;/groupId&gt; &lt;artifactId&gt;java-web-crawler&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>maven目录结构</tag>
        <tag>maven依赖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Notepad++中查找替换「换行符」]]></title>
    <url>%2F2019%2F02%2F26%2FNotepad%2B%2B%E4%B8%AD%E6%9F%A5%E6%89%BE%E6%9B%BF%E6%8D%A2%E3%80%8C%E6%8D%A2%E8%A1%8C%E7%AC%A6%E3%80%8D%2F</url>
    <content type="text"><![CDATA[Notepad++ 是 Windows 中一款优秀的文本编辑软件，功能非常强大。 重要说明： 1、为更好的理解本文，建议先阅读相关文章 – 不同操作系统中的换行符。 2、本文内容基于 Notepad++ 7.5.1 版本，为方便书写，若无特殊说明，下文中内容均指在该软件版本下的操作。 一、查找替换「换行符」1、设置「显示行尾符」为了更清楚的看到换行符的变化，首先进行下面设置：视图 -&gt; 显示符号 -&gt; 显示行尾符 然后新建一个文本，在其中随意输入内容，会看到显示「换行符」为 CRLF，即 \r\n。 2、查找并替换「换行符」 Ctrl + H，打开替换对话框，查找模式 选中 扩展 或者 正则表达式，使查找目标 和 替换为 中同时支持字符串和特殊字符的匹配； 然后在 查找目标 中输入 \r\n ，即可匹配到文本中的回车换行符； 在 替换为 中输入要替换成的字符即可； 二、扩展：查找替换「空行」、空白符下面列举常用的几种查找替换情况：（前提是要选中 正则表达式模式） 查找目标 替换为 说明 \r\n ,\r\n 在行尾加上逗号 \r\n 替换为空，即合并多行内容为一行 \r\n \n 把 windows 下的换行符替换为 linux 下的换行符 \n 把 \n 替换为空，即把 windows 下的换行符替换为 Mac 下的换行符 , \r\n 把逗号全部替换成换行 \r\n\r\n \r\n 去掉空行 1\s\s 1 去掉 1 后的两个空格，其中一个 \s 表示一个空格 1两个半角空格 1 可以直接在 1 后跟两个半角空格来匹配，跟上面 \s 是一样的效果 \r\n \r\n\t 在每行行首添加制表符，即四个半角空格的效果]]></content>
      <categories>
        <category>办公利器</category>
      </categories>
      <tags>
        <tag>Notepad++</tag>
        <tag>换行符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk 命令学习]]></title>
    <url>%2F2019%2F02%2F26%2Fawk%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[一、awk 介绍AWK是一种处理文本文件的语言，是一个强大的文本分析工具。 之所以叫AWK是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。 二、语法格式123awk [选项参数] 'script' var=value file(s)或awk [选项参数] -f scriptfile var=value file(s) table th:first-of-type{ width: 15%; } table th:last-of-type{ width: 55%; } 选项 第二种写法 参数说明 -F ‘fs’ -F 相当于内置变量 FS，即 field-separator -F 指定文件的分隔符，fs是一个字符串或者正则表达式，可以加引号也可以不加（最好加上单引号）； 默认不带 -F 参数时，使用空格或制表符等空白字符做为分隔符。 -v var=value –asign var=value 赋值一个用户定义变量 -f scripfile –file scriptfile 从脚本文件中读取awk命令 三、基本用法log.txt文本内容如下： 12342 this is a test3 Are you like awkThis's a test10 There are orange,apple,mongo 实例： 1、每行按空格或TAB分割，并输出文本中的第1、4项123456$ awk '&#123;print $1,$4&#125;' log.txt---------------------------------------------2 a3 likeThis's10 orange,apple,mongo 2、格式化输出123456$ awk '&#123;printf "%-8s %-10s\n",$1,$4&#125;' log.txt---------------------------------------------2 a3 likeThis's10 orange,apple,mongo 3、awk -F 指定分割字符3.1 使用 ,分割 -F 和分隔符之间可以有空格也可以没有，分隔符可以加单引号或双引号，也可以不加。 建议最好是 -F 和分隔符之间有一个空格，并给分隔符加单引号，不容易出错。 1234567# 文本中没有分隔符字符，所以 $1 就是全部文本，$2 是空。$ awk -F ',' '&#123;print $1,$2&#125;' log.txt---------------------------------------------2 this is a test3 Are you like awkThis's a test10 There are orange apple 3.2 使用 a分割123456$ awk -F 'a' '&#123;print $1&#125;' log.txt ---------------------------------------------2 this is 3 Are you like This's 10 There 3.3 使用多个分隔符先使用空格分割，然后对分割结果再使用”,”分割 123456$ awk -F '[ ,]' '&#123;print $1,$2,$5&#125;' log.txt --------------------------------------------- 2 this test 3 Are awk This's a 10 There apple 4、awk -v 设置变量常用语法： awk -v var=value &apos;{print $1,$2}&apos; filename 4.1 定义一个变量，并在输出时对变量进行运算数字与数字运算，结果正常； 数字与字符串运算，只保留数字。 123456$ awk -va=1 '&#123;print $1,$1+a&#125;' log.txt--------------------------------------------- 2 3 3 4 This's 1 10 11 4.2 定义多个变量，并在输出时对变量进行运算数字与数字运算，结果正常； 数字与字符运算，只保留数字； 字符或数字与字符拼接； 123456$ awk -va=1 -vb=s '&#123;print $1,$1+a,$1b&#125;' log.txt----------------------------------------------- 2 3 2s 3 4 3s This's 1 This'ss 10 11 10s 5、awk -f 指定脚本常用语法： awk -f {awk脚本} {文件名} 1$ awk -f cal.awk log.txt]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>awk</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区别 git clone 与 git pull]]></title>
    <url>%2F2019%2F02%2F26%2Fgit%20clone%26pull%EF%BC%8Cpull%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%EF%BC%8C%E6%89%B9%E9%87%8F%E6%8F%90%E4%BA%A4%2F</url>
    <content type="text"><![CDATA[1、git clone 与 git pull 相同点相同点：都是从远程服务器拉取代码到本地 2、git clone 与 git pull 不同点git clone是在本地没有版本库的时候，从远程服务器克隆整个版本库到本地，是一个本地从无到有的过程。 git pull在本地有版本库的情况下，从远程库获取最新commit 数据（如果有的话），并merge（合并）到本地。 git pull = git fetch + git merge 3、使用场景通常情况下，远程操作的第一步，是使用git clone从远程主机克隆一个版本库到本地。 本地修改代码后，每次从本地仓库push到远程仓库之前都要先进行git pull操作，保证push到远程仓库时没有版本冲突。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>git clone</tag>
        <tag>git pull</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建nGrinder性能测试平台并快速使用]]></title>
    <url>%2F2019%2F02%2F26%2F02_%E6%90%AD%E5%BB%BA%20nGrinder%20%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B9%B3%E5%8F%B0%20%E5%B9%B6%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[接上一篇的nGrinder介绍篇 一、nGrinder 组件介绍ngrinder包含Controller、agent 和 monitor 三部分 1、Controller 提供性能测试的web接口 协调测试进程 调整和显示测试的统计结果 让用户创建和修改脚本 2、Agent 在代理服务器上加载运行测试进程和线程 可以部署多台，提升压测能力 最好是能部署在单独的服务器上，如果没有条件的话，也可以跟Controller在一台服务器 但是不能部署在被测服务器上 3、Monitor 用于监控被测服务器的系统性能（例如：CPU/MEMORY） 必须部署在被测服务器上 二、nGrinder 环境搭建 $ java -XX:MaxPermSize=512m -jar ngrinder-controller-3.4.war –port 80可在下载ngrinder后，直接通过上面的命令运行也可以通过下面的方式，把war包放在tomcat容器中运行 1、安装JDK，配置环境变量2、安装Tomcat3、下载nGrinder：https://github.com/naver/ngrinder/releases4、把下载好的包放到Tomcat的webApps文件夹中5、启动Tomcat，并访问nGrinder nGrinder主页：http://localhost:8080/ngrinder-controller-3.4/ 看到下图表示搭建成功。 如果想直接通过http://localhost:8080/访问，把文件名改为ROOT.war即可 6、安装Agent 登录 nGrinder 管理台，默认账号和密码都是admin，点击右上角，选择 Download Private Agent (不同版本可能会稍有区别) ，如下图所示 把 ngrinder-agent 压缩包解压到用作Agent的服务器上，运行 run_agent.sh 即可 7、安装Monitor（需要安装在被测服务器上） 下载Monitor安装包，方法类似Agent 把 ngrinder-monitor 压缩包解压到被测服务器上，运行 run_monitor.sh 即可 补充说明： ngrinder支持开箱即用，不需要额外配置，第一次启动时，系统配置自动生成 默认使用H2数据库，且schema自动创建 版本更新时，数据库schema自动更新 agent 、monitor模块从controller下载，无需配置 版本更新时，只需更新controller，agent和monitor会自动更新 在线修改系统配置，多数据修改无需重启 即使用cluster模式，配置也很简单 三、快速使用1、输入测试URL，选择脚本语言，然后点击开始测试，会自动生成测试脚本并进入配置页面或者通过点击管理后上方的 script 或 脚本 按钮，进入脚本管理页面，创建脚本，效果相同。 在创建脚本时，可以选择使用的语言为Groovy或Jython，但是由于这两种语言执行性能上的差别，建议优先使用性能更好的Groovy来编写压测脚本（官方验证相同情况下groovy比jython支持2倍左右的并发数） 2、基本的压测配置 代理：是指压测所需要的server的数量 虚拟用户有两个指标： 进程数：每个server起多少进程去跑 线程数：每个进程新建的线程数量 并发量=代理数x进程数x线程数 Ramp-Up：设置增量测试，逐渐向最大的的并发量增长，只有勾选该框时，初始数、增量、初始等待时间、进程增长间隔的值才有效 测试时间：表示压测需要持续运行的时间测试次数：脚本执行的次数，同测试时间二选一 3、运行测试在配置页面右上角点击保存并运行，启动测试。 4、监控测试，查看结果当启动测试后，会在页面显示当前的TPS、虚拟用户、测试成功与否的数量等信息。测试完成后，会显示测试结果。 可以点击详细测试结果查看更详细的信息，比如TPS、平均时间、首次接受数据平均时间，以及被测服务器的CPU，MEM等信息。]]></content>
      <categories>
        <category>nGrinder</category>
      </categories>
      <tags>
        <tag>nGrinder</tag>
        <tag>nGrinder性能测试平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep命令详解]]></title>
    <url>%2F2019%2F02%2F26%2Fgrep%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[一、grep常用命令grep的功能是分析一行信息，过滤出包含指定内容的行。 ==需要注意的是它以整行为单位进行数据的选取==。 1、语法grep [-acinv] [--color=auto] &apos;要查找的字符串&apos; filename 参数 说明 -a 将binary文件以text文件的方式查找数据 -c 计算找到查找字符串的次数 -i 忽略大小写的不同 -n 输出行号 -E 同时匹配多个关键词 -r 遍历匹配 -w 整字匹配 -v 反向选择，显示出没有查找字符串的内容的行 -c 只输出匹配行的统计次数 –color-auto 将找到的字符串以特殊颜色显示 2、范例先将/etc目录下的man.config文件拷贝至/tmp文件夹下，来作实验: cd /tmp cp /etc/man.config . 2.1 grep ‘字符串’将文件中包含MANPATH的那一行取出来。 cat manpath.config | grep &apos;MANPATH&apos; 2.2 grep -v ‘字符串’与上例子相反，只要没有包含MANPATH的那一行就取出来。 cat manpath.config| grep -v &apos;MANPATH&apos; 2.3 grep -E 同时匹配多个关键字–或关系grep -E &quot;word1|word2|word3&quot; file.txt 匹配 file.txt 中包含 word1 或 word2 或 word3 的行。 满足其中任意条件（word1、word2和word3之一）就会匹配。 注意：多个关键字一定要放在双引号中，不然无法正常匹配。 不带双引号会报错，类似下面这样：1234grep &apos;update fail&apos;|ERROR|timeout appmonitor.log test.log* | wc -l -bash: ERROR: command not foundtimeout: 无效的时间间隔&quot;appmonitor.log&quot;请尝试执行&quot;timeout --help&quot;来获取更多信息。 加上双引号后正常：1grep &quot;&apos;update fail&apos;|ERROR|timeout&quot; appmonitor.log test.log* | wc -l 2.4 管道符连接多个 grep–同时匹配多个关键字–与关系grep word1 file.txt | grep word2 |grep word3 必须同时满足三个条件（word1、word2和word3）才匹配。 2.5 整字匹配搜索12345grep -w &quot;android&quot; logcat.txt 从logcat.txt文件中，搜索包含单词android的文本行grep -w &quot;android | ios&quot; logcat.txt 从logcat.txt文件中，搜索包含单词android或者ios的文本行 2.6 统计字符出现次数grep -c &quot;android&quot; . 二、grep的一些高级参数1、语法grep [-A] [-B] [--color=auto] &apos;查找字符串&apos; filename&apos; -A：后面可加数字，为after的意思，除了列出该行以外，后续的n行也列出来。 -B：后面可加数字，为before的意思，除了列出该行以外，前面的n行也列出。 2、范例1、用dmesg列出内核信息，然后用grep找出包含eth的那行，并且显示行号。而且将关键字的前2行和后3行也列出来。 dmesg | grep -n -A3 -B2 --color=auto &apos;eth&apos; 其中的 | 是管道符，用于把左边输出的内容传递给右边的命令 在关键字的显示上，grep可以用—color=auto来将关键字用特殊颜色显示。但是每次使用grep都得加上这个信息很麻烦，于是可以用alias进行一下处理就OK了。 可以在~/.bashrc内加上这一行：alias grep=’grep –color=auto’。 三、基础正则表达式练习1、与中括号[]结合 查找包含[]中某一个字符的内容12比如我要查找man或者men字符串，可以这样来查找：grep -n &apos;m[ae]n&apos; manpath.config 12查找包含man且man前面有数字的行：grep -n &apos;[0-9]man&apos; manpath.config Note：中括号[]里面不论有几个字符，它都只代表某一个字符。 2、与反向选择^结合使用 查找不包含指定字符的内容 12345查找包含man而且前面没有/的那一行：grep -n &apos;[^/]man&apos; manpath.config查找包含man但是前面不是小写字符的那一行：grep -n &apos;[^a-z]man&apos; manpath.config 3、与行首 ^ 和行尾 $ 字符结合12345678列出行首为MANPATH_MAP的行：grep -n &apos;^MANPATH_MAP&apos; manpath.config列出开头是大写字符的那一行：grep -n &apos;^[A-Z]&apos; manpath.config列出开头不是英文字母的行：grep -n &apos;^[^a-zA-Z]&apos; manpath.config ^ 符号在字符集合（中括号[]）之内和外面是不同的！！！ 在[]里面代表反向选择，在[]外面代表定位在行首的意思 反过来思考，使用$来查找行尾字符：123456找出行尾结束符为点.的行：grep -n &apos;\.$&apos; manpath.config因为小数点具有特殊的意义，所以必须用转义字符加以解除其特殊意义。查找出空白行：grep -n &apos;^$&apos; manpath.config 4、任意一个字符.与重复字符*在bash当中，通配符*可以用来代表任意（0或多个）字符，但是正则表达式并不是通配符，两者之间是不相同的。 在正则表达式当中： .代表绝对有一个字符的意思 *代表重复前一个字符0到无穷多次的意思，为组合形态 实例：12345查找包含一个o以上的行，需要oo*：grep -n &apos;oo*&apos; manpath.config查找以g开头与以g结尾，中间至少存在一个o的行：grep -n &apos;goo*g&apos; manpath.config 5、{}限定连续字符范围我们可以利用.与*来设置0到无穷多个重复字符。那如果要限制一个范围区间内的重复字符呢？ 比如要找出2-5个o的连续字符串，就要用到限定范围的字符{}了。 但是{}的符号在shell有特殊意义，因此要用到转义字符 \。 实例：123456找出g后面有两个到五个o，后面再接一个g的字符串：grep -n &apos;go\&#123;2,5\&#125;g&apos; manpath.config如果是2个以上呢：grep -n &apos;go\&#123;2,\&#125;g&apos; manpath.config这样就OK了。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>linux</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git一次性add多个文件或提交多次修改]]></title>
    <url>%2F2019%2F02%2F26%2Fgit%E4%B8%80%E6%AC%A1%E6%80%A7%20add%E5%A4%9A%E4%B8%AA%E6%96%87%E4%BB%B6%E6%88%96%E6%8F%90%E4%BA%A4%E5%A4%9A%E6%AC%A1%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[有时我们需要对 git 的修改操作进行批量提交，此时该怎么操作呢？ 按下面的步骤操作即可实现一次性add多个文件或提交多次修改： git add --all git commit -m &apos;add more files&apos; git push origin master]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>git add</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[intellij idea使用手册-03 导入和创建项目]]></title>
    <url>%2F2019%2F02%2F26%2Fintellij%20idea%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C-03%20%E5%AF%BC%E5%85%A5%E5%92%8C%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[idea导入maven项目1、import project -&gt; 选择本地的maven项目文件夹(包含pom.xml的文件夹) -&gt; import project from external model + Maven -&gt; ，然后选择下图中的选项 2、设置maven环境为本地自己下载的maven路径，及自己的仓库地址，override 3、select profiles -&gt; 选中public-snapshots -&gt; 配置sdk -&gt; 其它默认即可。 idea导入maven模块1、打开一个现有的idea工程 2、File –&gt;new–&gt; module from existing sources –&gt; Select File or Directory to Import根据不同的项目类型选择不同的文件，如Maven项目选中pom.xml， 点击 finish 即可导入完成。 3、然后在 terminal 命令行中测试导入的项目是否可以正常运行。如：mvn test, mvn package, mvn install。 idea 本地创建 maven项目1、本地搭建 maven 环境下载解压 maven，修改配置文件 settings.xml（最好用sublime Text3 编辑，避免改错），设置本地仓库。 2、idea 创建一个 maven 管理的 web 项目（1）Create New Project -&gt; Maven -&gt; maven-archetype-webapp -&gt; 填写项目名称 -&gt; 选择maven home ， 路径为自己下载的 maven 路径（不用 idea 自带的bundled版本） -&gt; User settings file 选中 Override。 （2）第一次创建项目非常慢（尤其是没网的状态下），要等右下角进度条完成后再操作。 （3）创建成功后，检查目录结构是否正确，src -&gt; main -&gt; webapp -&gt; web-inf，若目录结构不正确，说明操作有误，删除重新创建。 idea 导入和打开项目的区别idea 导入(import)项目和打开(open)项目稍微有点区别。 如果你要使用的项目是 idea 模型的项目，既原来就是用 idea 开发的，那么直接 open 打开就可以了。 如果你要使用的项目不是 idea 模型的项目，既原来不是用 idea 开发的，如用 eclipse 开发的项目，没有 impl 文件，这时直接 open 打开会有很多报错，需要选择导入项目 import。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>intellij idea</tag>
        <tag>IDEA导入项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 中配置用户变量和环境变量]]></title>
    <url>%2F2019%2F02%2F26%2Flinux%20%E5%8F%98%E9%87%8F%20%26%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[一、系统变量1、env显示系统环境变量，直接输入env即可。 2、set在env的基础上增加显示了用户自定义的变量，直接输入set即可。 二、自定义变量1、变量名规则：变量名只能包含字母、数字、下划线，且首位不能是数字。 a=1 a=abc a=a37 2、变量值 变量值有特殊符号时需要用单引号括起来 如果用双引号，会识别其中的特殊字符；单引号会把其中的特殊字符当作普通字符来处理。 调用变量时，使用$加上变量名即可。1234567891011121314没有特殊字符时，单引号和双引号效果相同：[app@centos tmp]$ a=&apos;a b c&apos;[app@centos tmp]$ echo $aa b c[app@centos tmp]$ a=&quot;b c&quot;[app@centos tmp]$ echo $ab c有特殊字符时，单引号和双引号效果不同：[app@centos tmp]$ echo $aa[app@centos tmp]$ a=&apos;a$bc&apos;[app@centos tmp]$ echo $aa$bc 3、连接多个变量也称为变量的累加。 调用时直接连接多个变量即可，依次计算出变量的值后，连接在一起。 多个变量连接时，最好把每个变量都用双引号括起来。 示例： 1234567891011121314151617181920212223242526定义变量a、b：[app@centos tmp]$ a=1[app@centos tmp]$ b=2两个变量直接相连：[app@centos tmp]$ echo $a$b12变量值中包含特殊字符时也可以直接相连：[app@centos tmp]$ a=&apos;a$b&apos; 修改了变量a的值[app@centos tmp]$ echo $a$ba$b2[app@centos tmp]$ c=&quot;c$b&quot; [app@centos tmp]$ echo $a$c 其中$c值为c2a$bc2当$后跟有多个字母时，均视为一个变量名，所以需要分开写：[app@centos tmp]$ c=c&quot;$bc&quot;[app@centos tmp]$ echo $cc把&quot;$bc&quot;分开成&quot;$b&quot;c，不然不能识别$b[app@centos tmp]$ c=c&quot;$b&quot;c[app@centos tmp]$ echo $cc2c 4、全局变量export 变量名=变量值 export b=123 把变量b设置为全局变量，且值为123 5、unset取消变量unset 变量名 注意：不加$ 12345[app@V]$ b=123[app@V]$ echo $b123[app@V]$ unset b[app@V]$ echo $b 三、自定义命令行前缀 PS1默认情况下，linux中命令行前缀显示的是黑色的，内容是：123非root用户：[用户名@主机名 路径名]$root用户：[用户名@主机名 路径名]# 其实这是由环境变量 PS1 控制的。 12345678910查看PS1变量的值：[app@xxx]$ echo $PS1[\u@\h \W]\$默认情况下PS1=&apos;[\u@\h \W]\$&apos;其中`\W`代表相对路径，`\w`代表绝对路径 修改PS1自定义命令前缀的颜色：PS1=&apos;[\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;36m\]\W\[\033[00m\]]\$ &apos; 当然，这样直接修改，只在当前会话中生效，若要所有会话生效，设置成全局变量即可。 四、环境变量配置文件 profile需要登录才生效，同时会调用bashrc。 bashrc不需要用户登录，执行shell就生效。 1、系统层次的123/etc/profile/etc/bashrc 2、用户层次的只对当前用户生效的配置：1234567~/.bashrc~/.bash_profile~/.bash_history~/.bash_logout 当前用户退出时执行的命令]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux系统变量</tag>
        <tag>linux环境变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统查看各种信息]]></title>
    <url>%2F2019%2F02%2F26%2Flinux%E7%B3%BB%E7%BB%9F%E6%9F%A5%E7%9C%8B%E5%90%84%E7%A7%8D%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[一、查看操作系统信息1、uname -a 查看操作系统信息$ uname -a Linux VM_101_50_centos 2.6.32-642.6.2.el6.x86_64 #1 SMP Wed Oct 26 06:52:09 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux 2、cat /etc/issue 查看内核$ cat /etc/issue CentOS release 6.3 (Final) Kernel \r on an \m 3、cat /etc/redhat-release # 查看内核$ cat /etc/redhat-release CentOS release 6.3 (Final) 4、其它hostname # 查看计算机名 env # 查看环境变量 二、查看CPU、内存、网络等资源信息1、常用命令1234567top # 实时显示进程状态free -m # 查看内存使用量和交换区使用量df -h # 查看各分区使用情况du -sh &lt;目录名&gt; # 查看指定目录的大小 2、查看网络12345ifconfig # 查看所有网络接口的属性netstat -lntp # 查看所有监听端口netstat -antp # 查看所有已经建立的连接netstat -s # 查看网络统计信息 3、查看进程和程序1234ps -ef # 查看所有进程 程序： rpm -qa # 查看所有安装的软件包 4、查看详细CPU信息/proc/cpuinfo12345678910111213141516171819202122232425262728$ cat /proc/cpuinfo processor : 0vendor_id : GenuineIntelcpu family : 6model : 63model name : Intel(R) Xeon(R) CPU E5-26xx v3stepping : 2microcode : 1cpu MHz : 2397.222cache size : 4096 KBphysical id : 0siblings : 1core id : 0cpu cores : 1apicid : 0initial apicid : 0fpu : yesfpu_exception : yescpuid level : 13wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx lm constant_tsc rep_good unfair_spinlock pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm xsaveoptbogomips : 4794.44clflush size : 64cache_alignment : 64address sizes : 40 bits physical, 48 bits virtualpower management:....有几核就会显示几块信息.... 5、查看详细内存信息/proc/meminfo12345678910111213141516171819202122232425262728293031323334353637383940414243$ cat /proc/meminfo MemTotal: 16332028 kBMemFree: 192596 kBBuffers: 9028 kBCached: 1082200 kBSwapCached: 220488 kBActive: 13422780 kBInactive: 2244716 kBActive(anon): 12885068 kBInactive(anon): 1706192 kBActive(file): 537712 kBInactive(file): 538524 kBUnevictable: 0 kBMlocked: 0 kBSwapTotal: 8191996 kBSwapFree: 1180728 kBDirty: 684 kBWriteback: 0 kBAnonPages: 14356000 kBMapped: 40076 kBShmem: 14992 kBSlab: 235844 kBSReclaimable: 183452 kBSUnreclaim: 52392 kBKernelStack: 39776 kBPageTables: 68364 kBNFS_Unstable: 0 kBBounce: 0 kBWritebackTmp: 0 kBCommitLimit: 16358008 kBCommitted_AS: 26461844 kBVmallocTotal: 34359738367 kBVmallocUsed: 42328 kBVmallocChunk: 34359687928 kBHardwareCorrupted: 0 kBAnonHugePages: 12441600 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBDirectMap4k: 8184 kBDirectMap2M: 16769024 kB 三、系统日志文件123456/var/log/message 系统启动后的信息和错误日志，是Red Hat Linux中最常用的日志之一 /var/log/secure 与安全相关的日志信息 /var/log/maillog 与邮件相关的日志信息 /var/log/cron 与定时任务相关的日志信息 /var/log/spooler 与UUCP和news设备相关的日志信息 /var/log/boot.log 守护进程启动和停止相关的日志消息]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>liunx系统信息</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven学习02-pom文件]]></title>
    <url>%2F2019%2F02%2F26%2Fmaven%E5%AD%A6%E4%B9%A002-pom%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[一、POM 文件是什么？Maven的中心思想即POM文件（(Project Object Model)项目对象模型）。 POM文件是以XML文件的形式，描述项目用到的资源，如源码目录、测试代码目录、依赖（用到的外部Jar包）等。 pom.xml 是整个系统的基础组件，位于项目根目录下。 二、Maven 如何使用POM文件？ 上图说明了Maven是如何使用POM文件的，当执行一条Maven命令的时候，会依次进行以下步骤： 1、读取项目根目录下的pom.xml，并根据pom.xml中的描述来执行下一步操作。 2、根据pom.xml中的&lt;dependencies&gt;，下载依赖到本地仓库中。 3、构建生命周期、阶段和目标。 4、构建插件。 三、POM文件的主要组成部分POM文件描述的是构建“什么”，而不是“如何”构建。 如何构建是取决于Maven的构建阶段和目标。 每一个项目都有一个POM文件，即pom.xml，位于项目的根目录下。 pom.xml 主要包括以下几部分： 3.1 构建生命周期、阶段和目标Maven的构建过程被分解为构建生命周期、阶段和目标。 &lt;build&gt; -&gt; &lt;phase&gt; -&gt; &lt;goals&gt; 一个构建周期由一系列的构建阶段组成。 每一个构建阶段由一系列的目标组成。 当我们使用一条命令来运行Maven的时候，这条命令就是构建生命周期、阶段或目标的名字。 如果执行的是一个生命周期，该生命周期内的所有构建阶段都会被执行。 如果执行的是一个构建阶段，在预定义的构建阶段中，所有处于当前构建阶段之前的阶段也都会被执行。 3.2 依赖和仓库&lt;repository&gt; 仓库节点，&lt;dependencies&gt; 依赖节点 Maven执行时，其中一个首要目标就是检查项目的依赖（需要的jar 包）。 如果在本地仓库中不存在该依赖，则Maven会从中央仓库和远程仓库下载并放到本地仓库。（后面会单独讲解怎么修改本地仓库路径、怎么添加远程仓库） 3.3 构建插件&lt;plugins&gt; 节点 构建插件可以向构建阶段中增加额外的构建目标。 如果Maven标准的构建阶段和目标无法满足项目构建的需求，可以在POM文件里增加插件。 Maven有一些标准的插件供选用，如果需要也可以自己实现插件。 3.4 配置文件&lt;profiles&gt; 节点 配置文件用于以不同的方式构建项目。 比如，你可能需要在本地环境构建，用于开发和测试，你也可能需要构建后用于开发环境。这两个构建过程是不同的。 在POM文件中增加不同的构建配置，可以启用不同的构建过程。当运行Maven时，可以指定要使用的配置。 四、Maven 项目继承1、父子工程中的POM（以下内容中子项目 与 模块的概念是类似的，所以也可以对应的理解为模块） 一个项目如果分为多个子项目/模块，一般来讲，父项目有一个POM文件，每一个子项目也有一个POM文件。在这种结构下，既可以一步构建整个项目，也可以各个子项目分开构建。 2、 POM 继承的原理POM 继承的原理类似于Java中的类继承关系，可以结合理解。 当有多个子项目时，使用 POM 继承可以大大减少配置的工作量。 把多个子项目之间一些共性的东西（比如说类似的配置、相同的jar包等等），定义在父项目的pom.xml文件中。 子项目继承父项目后，在自己的pom.xml中只放自己个性的东西，大大减少了工作量。 默认情况下，所有的Maven pom文件都继承自一个根pom。如果没有显式指定父pom，则该pom文件继承自根pom。 子pom文件的设置可以覆盖父pom文件的设置，只需要在子pom文件里指定新的设置即可。 3、POM继承关系图 如果要继承根pom以外的pom，需要在子pom中显示地指定父pom。 4、如何显示指定父pom呢？ 在子项目的pom.xml起始处设置 &lt;parent&gt; 节点来指定父项目。如：12345678910111213141516&lt;project xmlns="http://maven.apache.org/POM/4.0.0"xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xsi:schemaLocation="http://maven.apache.org/POM/4.0.0http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;parent&gt; 指定父pom&lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;&lt;artifactId&gt;my-parent&lt;/artifactId&gt;&lt;version&gt;2.0&lt;/version&gt;&lt;relativePath&gt;../my-parent&lt;/relativePath&gt;&lt;/parent&gt;&lt;artifactId&gt;my-project&lt;/artifactId&gt;…&lt;/project&gt; 五、POM文件字段解析如下为一个最小化的POM文件示例：12345678910&lt;project xmlns="http://maven.apache.org/POM/4.0.0"xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xsi:schemaLocation="http://maven.apache.org/POM/4.0.0http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.jenkov&lt;/groupId&gt;&lt;artifactId&gt;java-web-crawler&lt;/artifactId&gt;&lt;version&gt;1.0.0&lt;/version&gt;&lt;/project&gt; 1、各字段解析 modelVersion：使用的POM模型的版本。 一般选择正在使用的Maven版本一致的版本即可。 版本4.0.0适用于Maven 2和3。 groupId：一个组织或者项目（比如开源项目）的唯一ID。一般使用项目的java包的根名称作为group ID。类似com.xxx.xxxx 。 使用带.分隔符的java包名作为groupId，这一点并不是必须的。 但是，如果按照这样的规范来定义groupId，项目将会位于Maven仓库的结构化目录中，该结构化目录与group ID匹配。每一个.是一个目录分隔符，每一个词都表示一个目录。 比如：group ID为com.jenkov的项目将位于目录MAVEN_REPO/com/jenkov中。目录路径中的MAVEN_REPO表示Maven仓库的路径。 artifactId：正在构建的项目的名称。 它也是构建完项目后生成的jar包的文件名的一部分。构建过程的输出，即构建结果，在Maven中称为构件（artifact）。通常它就是一个jar包、war包或者EAR包等等。 version：项目的版本号。 可以用来识别项目不同的发行版。 它是artifact ID目录下的子目录名。 它也用作构建结果即jar包名称的一部分。 上文中的groupId，artifactId和version属性，在项目构建后会生成一个jar文件，位于Maven仓库的如下路径中（目录和文件名）：MAVEN_REPO/com/jenkov/java-web-crawler/1.0.0/java-web-crawler-1.0.0.jar 上面只是构建maven项目最基本的一些配置，实际开发中，还会增加更多的配置来辅助构建。]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>pom文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[intellij idea 和 eclipse 区别（IDEA使用手册01）]]></title>
    <url>%2F2019%2F02%2F26%2Fintellij%20idea%20%E5%92%8C%20eclipse%20%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[一、IDEA 和 eclipse 对比 IDEA Eclipse 说明 new Project workspace 创建 项目/工作空间，是最顶级的结构单元 new Module new Project 创建一个模块/工程，一个 Project/工作空间 下可以有多个 模块/工程 文件自动保存，不能设置为手动保存 需要手动保存 智能提示重构代码,告诉你更好的实现方式 更友好、更聪明的代码提示功能 二、IntelliJ IDEA 中的 Project 和 Module在 IntelliJ IDEA 中，没有类似于 Eclipse 工作空间（Workspace）的概念，而是提出了Project和Module这两个概念。 2.1 Project : Module = 1 : n在 IntelliJ IDEA 中Project是最顶级的结构单元，下面是一个或多个Module，是一对多的关系。 2.2 多个 Module 的划分在大型项目中，都是使用多 Module 结构，按功能不同划分为多个模块，模块之间可以相互依赖。 2.3 Project 对 Module 的意义 IDEA 的 Project 可以简单地理解为是一个单纯的目录，下面存放不同模块的文件夹。 Project 主要起到一个项目定义、范围约束、规范类型的效果，本身不具备任何编码设置、构建等开发功能。 2.4 Project 和 Module 的默认配置 IDEA 默认是单 Project 单 Module 结构，且默认名字相同，这时二者合二为一； 当一个 Project 下有多个 Module 时，最好是使用不同的名字。 三、安装目录进入IntelliJ IDEA 安装目录的bin目录下 （bin是 binary 的缩写，代表的意思是二进制，因此bin目录就是用来存放二进制文件） 在这里，我们主要了解下面五个文件： idea.exe：IntelliJ IDEA 32 位的可行执行文件，IntelliJ IDEA 安装完默认发送到桌面的就是这个执行文件的快捷方式； idea.exe.vmoptions：IntelliJ IDEA 32 位的可执行文件的 VM 配置文件； idea.properties：IntelliJ IDEA 的一些属性配置文件； idea64.exe：IntelliJ IDEA 64 位的可行执行文件，要求电脑上必须装有 JDK 64 位版本，64 位的系统也是建议使用该文件； idea64.exe.vmoptions：IntelliJ IDEA 64 位的可执行文件的 VM 配置文件。 四、新建项目通过Create New Project，选择需要的项目类型，然后设置项目和模块的名称和存储路径。 默认是一个Project下创建一个Module，因此创建时项目名称与模块名称默认是相同的。一般情况下，我们是不需要在More Settings中进行修改的。 默认界面是隐藏Toolbar和Tool Buttons的，可以通过view--&gt;Toolbar和Tool Buttons 来开启。 在创建 java project 时，默认使用的是自带的JRE，在 Project SDK 中选择自己下载的jdk目录。 创建完成后，会在IDEA左侧显示项目结构图和外部库 在项目结构图中，src目录为默认的Source root，我们一般在该目录下创建包和类； 在外部库中，显示了我们导入的 JDK 1.8 版本 五、创建包和类5.1 创建包 在 src 中创建包时，可以一次创建多个包，如：输入包名为 com.hit.demo，同时创建了三个空包。 创建的多个空包默认是重叠在一起的，如果其中某个包非空，则自动拆开包。 如果感觉空包叠在一起不爽的话，可以点击旁边的齿轮按钮，再点击 Hide Empty Middle Packages 把对勾去掉，变为 Compact Empty Middle Packages，就会把空包都按树状展示。 5.2 创建类 在一个包上点击鼠标右键，选择 Create Java Class ,创建 HelloWorld 类。 编写完成代码后，直接在编辑区右键–Run HelloWorld 运行类。 然后会在左侧目录中生成一个与 src 同级的目录 out ，用于存放项目中所有Module的编译文件。 六、项目中的配置文件6.1 .idea 目录这是整个 Project的配置文件目录。 IntelliJ IDEA 的配置文件都存在.idea目录下，以 XML 文件的形式存在，因此我们也可以通过了解这些 XML 文件来了解 IntelliJ IDEA 的相关配置。 6.2 .iml 文件这个文件是Module的配置文件。 这是 IntelliJ IDEA 为每个 Module 自动生成的配置文件，一般情况下不需要动。 七、设置主题和字体7.1 界面主题修改Files -&gt; Settings -&gt; Appearance &amp; Behavior -&gt; Appearance 在 Windows 系统上 IntelliJ IDEA 默认提供三个主题，分别为：Darcula、IntelliJ和Windows。其中，除了Darcula是黑色背景的主题，其余两个都是白色背景的主题。 7.2 界面字体修改Appearance &amp; Behavior &gt; Appearance 选中 Override default fonts by XXX ，并设置具体字体大小的数值。 这里的修改不会应用于代码编辑区！ 有一点需要注意，那就是：有的字体是包含中文的，有的字体则是不包含中文的。 一般情况下，使用英文的国家是不需要额外担心乱码问题的，但是我们需要啊！ 如果我们选择的字体不包含中文的话，很多位置上可能会出现类似于 口口口口口 这样的乱码问题。 例如，Courier New和Monaco就是纯英文字体，而Microsoft YaHei就是包含中文的字体。 7.3 代码编辑区主题修改Files -&gt; Settings -&gt; Appearance &amp; Behavior -&gt; Editor &gt; Color Scheme 在 Windows 系统上 IntelliJ IDEA 默认提供两个编辑区主题，分别为：Default和Darcula。其中，Default为默认主题；Darcula为黑色主题。 7.4 代码编辑区和控制台的字体修改Editor &gt; Font 这里的设置可以同时应用于代码编辑区和控制台 Font ：设置第一字体 Show only monospaced fonts：仅显示等宽字体，默认是勾选状态，可选的字体较少，可去掉勾选。 Fallback font：备选字体，如果首选字体中无法显示文字，系统就会自动调用备选字体来显示。例如首选字体我们可以设置为英文字体，备选字体设置为中文字体，这样即可优美的显示代码，而中文也不会变为‘口口’字 Enable font ligatures：是否启用字体连写，一般不启用。 7.5 设置 Sublime 代码颜色的方法在使用 Sublime 时，五颜六色的代码看起来非常美观，怎么让 IDEA 也设置成类似的格式呢？ 下载「SublimeMonoKaiTrue」jar 包 https://github.com/guobinhit/intellij-idea-tutorial/tree/master/resources/idea-theme/SublimeMonokaiTrue.jar； File -&gt; Import Settings，导入已经下载完的「SublimeMonoKai.jar」包，按提示重启 IDEA ； 重启后，默认就会使用新的 sublime 主题效果了，具体可以在 File -&gt; Settings -&gt; Editor -&gt; Color Scheme 中修改。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>intellij idea</tag>
        <tag>eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux管道符和作业控制]]></title>
    <url>%2F2019%2F02%2F26%2Fshell%20%E7%AE%A1%E9%81%93%E7%AC%A6%26%E4%BD%9C%E4%B8%9A%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[一、管道符 | 把前面命令输出的结果，传递给后面的命令。 示例：12345678统计文件的行数cat 1.txt | wc -l过滤文件内容cat 1.txt | grep aaa查看当前目录下有多少个文件：find ./ -type f | wc -l 二、作业控制1、Ctrl C停止一个任务 在执行一个命令的过程中，彻底停止一个任务。 执行之后，jobs查看不到该任务。 1234[app@centos tmp]$ sleep 10^C[app@centos tmp]$ jobs[1]+ Stopped sleep 100 2、Ctrl Z 暂停一个任务 在执行一个命令的过程中，暂停一个任务。 执行之后，jobs可以查看到该任务。 12345[app@centos tmp]$ sleep 100^Z[1]+ Stopped sleep 100[app@centos tmp]$ jobs[1]+ Stopped sleep 100 注意： 执行Ctrl C 和 Ctrl Z之后，都会显示 Stopped 状态，但是Ctrl Z的任务只是被暂停了，可以通过jobs进行调度。 3、jobs 查看后台的任务 查看当前会话窗口中后台任务，包括名称和命令序号id 包括被ctrl z暂停的任务 和 被 &amp;放入后台运行的任务123456789[app@centos tmp]$ sleep 10^Z[1]+ Stopped sleep 10[app@centos tmp]$ sleep 20^Z[2]+ Stopped sleep 20[app@centos tmp]$ jobs[1]- Stopped sleep 10[2]+ Stopped sleep 20 4、bg[id]把任务调到后台并运行 bg即background，把被暂停的任务放入后台运行 后面加上作业id号可以指定某一个作业，不加id时默认最近的一个作业。 示例： （注意下面命令中的状态变化）12345678[app@centos tmp]$ jobs[2]- Stopped sleep 20[3]+ Stopped sleep 50[app@centos tmp]$ bg 3[3]+ sleep 50 &amp;[app@centos tmp]$ jobs[2]+ Stopped sleep 20[3]- Running sleep 50 &amp; 5、fg[id]把任务调到前台 fg即foreground，把后台作业调到前台运行 后面加上作业id号可以指定某一个作业，不加id时默认最近的一个作业。 示例： 把被暂停的任务调到前台继续运行： 6、&amp;把任务放入后台运行 直接在命令后面加&amp;即可 命令在后台是Running状态 相当于对命令执行Ctrl Z 和 bg 1234567[app@centos tmp]$ jobs[2]+ Stopped sleep 20[app@centos tmp]$ sleep 50 &amp;[3] 12580[app@centos tmp]$ jobs[2]+ Stopped sleep 20[3]- Running sleep 50 &amp;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>管道符</tag>
        <tag>linux作业控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell通配符和输入输出重定向]]></title>
    <url>%2F2019%2F02%2F26%2Fshell%20%E9%80%9A%E9%85%8D%E7%AC%A6%26%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[一、shell 常用通配符1、* 匹配一个或多个任意的字符12345*.txt*txt*txt* 2、? 匹配一个任意的字符?.txt 3、[] 匹配一个范围中的一个字符1234567ls [123].txtls [1-3].txtls [0-9a-z].txtls [0-9a-zA-Z].txt 4、{} 匹配其中的一个字符，类似于[] {}和[]类似，都是匹配里面的其中一个字符 区别是：[]支持范围，{}不支持范围12345678910ls &#123;1,2,3,a,b&#125;.txtls &#123;1,2&#125;.txt## &#123;&#125; 和 [] 的区别：[app@centos tmp]$ ls &#123;1-3&#125;.txtls: cannot access &#123;1-3&#125;.txt: No such file or directory[app@centos tmp]$ ls [1-3].txt1.txt 2.txt 二、输入输出重定向1、&gt; (正确)输出重定向（重写）cat 1.txt &gt; 2.txt # 把1.txt中的内容写入2.txt； # 若2.txt在写入前非空，会先清除原有内容后再写入。 2、&gt;&gt; (正确)输出重定向（追加）cat 1.txt &gt;&gt; 2.txt # 把1.txt中的内容追加在2.txt原有内容之后 3、2&gt; 错误输出重定向（重写）lsaaa 2&gt; err.log # 把左边命令执行后的错误信息输出到err.log中； # 如果err.log在输出前非空，会先清除原有内容后再输出。 4、2&gt;&gt;错误输出重定向（追加）lsaaa 2&gt;&gt; err.log # 把左边命令执行后的错误信息追加到err.log原有内容后面，不会清除原有内容。 5、&amp;&gt;（重写）重定向正确和错误的信息 把&amp;&gt;左边命令执行后产生的正确和错误的所有信息，输出到 &amp;&gt;右边的文件中（先清除文件内容）。 等价于 &gt; 和 2&gt; 结合使用123456[app@centos tmp]$ ls1.txt[app@centos tmp]$ ls 1.txt 2.txt &amp;&gt; log[app@centos tmp]$ cat logls: cannot access 2.txt: No such file or directory1.txt 6、&amp;&gt;&gt;（追加）重定向正确和错误的信息 把&amp;&gt;&gt;左边命令执行后产生的正确和错误的所有信息，追加输出到 &amp;&gt;&gt;右边的文件中。 等价于 &gt;&gt; 和 2&gt;&gt; 结合使用 12345678[app@centos tmp]$ ls1.txt log[app@centos tmp]$ ls 1.txt 2.txt &amp;&gt;&gt; log[app@centos tmp]$ cat logls: cannot access 2.txt: No such file or directory1.txtls: cannot access 2.txt: No such file or directory1.txt 7、&gt; 和 2&gt; 结合，分别输出正确和错误的信息12345678910[app@centos tmp]$ ls1.txt 2.txt log[app@centos tmp]$ ls [12].txt a.txt &gt; 1.txt 2&gt; err.log# 把命令执行后生成的正确信息重写输出到1.txt，错误信息重写输出到err.log[app@centos tmp]$ cat 1.txt1.txt2.txt[app@centos tmp]$ cat err.log ls: cannot access a.txt: No such file or directory 8、&lt; 输入重定向 把&lt; 右边的文件内容输入给左边的命令后，执行左边的命令 左边必须是一个命令，不能是文件123456789[app@centos tmp]$ cat 1.txt 12[app@centos tmp]$ wc -l &lt; 1.txt2[app@centos tmp]$ 2.txt &lt; 1.txt-bash: 2.txt: command not found## 左边必须是命令！]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>通配符</tag>
        <tag>输入输出重定向</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell标准输入read和输出echo]]></title>
    <url>%2F2019%2F02%2F26%2Fshell%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5read%E5%92%8C%E8%BE%93%E5%87%BAecho%2F</url>
    <content type="text"><![CDATA[一、标准输入 readshell 中通过 read 语句从键盘或文件的某一行文本中读入信息，并将内容赋给变量，多个变量之间用空格分隔。 read 变量1 变量2 ... ==read 每次只能读取一行数据。== 把一行内容全部赋值给一个变量，并直接通过 echo 输出。 123456789$ read name jjing$ echo $name jjing $ read name jjing jj$ echo $name jjing jj 一次赋值多个变量，多个值用空格分隔。 123456$ read name1 name2 jjing tao$ echo $name1 jjing$ echo $name2 tao 赋值多个变量时，当值多于变量名时，最后多余的内容全部赋值给最后一个变量。 123456$ read name1 name2 jjing tao yayaa$ echo $name1 jjing$ echo $name2 tao yayaa 二、标准输出 echo使用 echo 命令可以输出文本字符串、变量、表达式、命令等。 直接在 echo 后面加上要输出的内容即可。 命令 输出内容 说明 echo “abcd1234” abcd1234 输出一个普通字符串，默认在结尾包含换行符，光标定位在下一行开头。 echo -e “my name is :\c” my name is : \c表示不换行，输出字符串后光标定位在字符串末尾。(在 Linux 中要加上 -e 参数才能生效) echo -e “1\n2\n3\n4\n” 输出多行，每个数字为一行 \n表示换行，实现一次性输出多行内容。(在 Linux 中要加上 -e 参数才能生效) a=1 echo “$a” 输出变量，使用 $ 引用变量名即可 引用变量时，可以不加双引号，但是不能用单引号。 echo “\“13242\“”echo ‘“13242”‘ “13242” 输出特殊字符时要转义，也可以在最外层使用单引号则不用转义。 echo “`date`“ 2018年 12月 20日 星期四 09:08:25 CST 输出命令 date的返回值。 说明： 输出内容可以带引号，也可以不带，但是为了书写规范及减少错误，最好统一带双引号。 \c–不换行，\n–换行，使用时前面要加上 -e参数。 输出变量时，直接用 $ 加上变量名即可。 输出特殊字符时，要使用 \转义，或者在最外层加上单引号，可以原文输出为字符串。 输出命令时，注意命令外面的特殊引号。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>输入输出</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort排序、uniq去重、wc统计]]></title>
    <url>%2F2019%2F02%2F26%2Fsort%E6%8E%92%E5%BA%8F%E3%80%81uniq%E5%8E%BB%E9%87%8D%E3%80%81wc%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[一、sort 排序 sort命令用于 对文本文件内容，以行为单位来排序。 sort命令以空格作为字段分隔符，将一行分割为多个关键字对文件进行排序。 需要注意的是除非你将输出重定向到文件中，否则sort命令并不对文件内容进行实际的排序(即文件内容没有修改)，只是将文件内容按有序输出。 1、语法sort [-bcdfimMnr][-o&lt;输出文件&gt;][-t&lt;分隔字符&gt;][+&lt;起始栏位&gt;-&lt;结束栏位&gt;][--help][--verison][文件] 2、参数说明 参数 说明 -m 将几个排序好的文件进行合并。 -u 内容去重 -n 依照数值的大小排序，升序排列。 -o&lt;输出文件&gt; 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。 -k&lt;指定排序的列数&gt; 指定要排序的列数，默认是从第一列开始比较，-k可指定某一列，也可与-t 结合使用时，代表某一栏 +&lt;起始栏位&gt;-&lt;结束栏位&gt; 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。 3、实例（1）对文件进行升序排序 sort testfile 以行为单位，相互比较，从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。 注意：原文件内容并未被修改！ （2）对文件进行升序排序，并去除重复行 sort -u sort -u 1.txt 可以看出： sort -u是先对内容进行排序，然后再去重（实际也是去除了相邻的重复行）。 而uniq不能实现排序，只能去除相邻的重复行，所以要跟sort合并使用，先用sort排序，再用uniq去重 sort 1.txt | uniq （3）按数值大小降序排列后，把结果再输出到原文件中 -o （直接用重定向做不到）1234sort -nr num.txt -o num.txt如果用重定向 &gt; 的方式，只会把num.txt清空！sort -nr num.txt &gt; num.txt（4）使用sort的-t选项和-k选项，设置间隔符后再指定排序的列如上图所示，对年月日的日期进行排序，直接使用sort dat.txt时，会按列从左到右来排序； sort -t’-‘ -k2 dat.txt 其中-t’-‘ 是以 ‘-’ 为分隔符对每行内容分栏，然后-k 2 表示对分栏后的第二栏内容进行默认的升序排列。（5）使用sort -k指定以某一列排序 sort -k9 a.txt （基于a.txt的第九列来排序）（6）sort命令并非仅能对文件进行排序，我们还可以通过管道将命令的输出内容重定向到sort命令中 ls -l /home/$USER | sort -nk5（7）对/etc/passwd以‘：’分隔，再以第六个域的第2个字符到第4个字符进行正向排序，再基于第一个域进行反向排序。12345cat /etc/passwd | sort -t&apos;:&apos; -k 6.2,6.4 -k 1r sync:x:4:65534:sync:/bin:/bin/syncproxy:x:13:13:proxy:/bin:/bin/shbin:x:2:2:bin:/bin:/bin/shsys:x:3:3:sys:/dev:/bin/sh# 二、uniq 去重## 1、uniq使用- uniq命令用于去重文件内容中的连续重复行，通常要跟sort一起使用，先利用sort排序，然后用uniq去重。- uniq命令与sort命令类似，并不对文件内容进行实际的排序(即文件内容没有修改)，只是在输出内容中去重。- uniq -c ：在输出行前面加上每一行重复的次数- uniq -d ：仅显示重复行- uniq -u ：仅显示不重复的行- uniq -n ：前n个字段与每个字段前的空白一起被忽略。一个字段是一个非空格、非制表符的字符串，彼此由制表符和空格隔开（字段从0开始编号）。- uniq +n ：前n个字符被忽略，之前的字符被跳过（字符从0开始编号）。## 2、sort和uniq去重结果对比1、sort -u使用sort对文件去重 sort -u 1.txt可以看出，sort -u是先对内容进行排序，然后再去重（实际也是去除了相邻的重复行）。2、使用uniq对文件去重可以看出，当内容中的重复行不相邻时，直接使用uniq 1.txt 并不能达到去重。 因为uniq只能去除相邻的重复行，所以要跟sort合并使用，先用sort排序，再用uniq去重sort 1.txt | uniq。 3、最常用的方式实际工作中，最常用的方式是sort和uniq结合： sort -n 1.txt | uniq -c 4、只显示文件中不重复的行uniq -u 1.txt 5、uniq -u -n 结合使用显示文件 1.txt 中不重复的行，从第2个字段的第2个字符开始做比较。 uniq -u -1 +1 1.txt 三、wc 统计wc命令用于统计文件里面有多少行，多少单词，多少字符。 常与sort、grep等其它命令结合使用。 参数 说明 -l line，统计行数； -w word，统计单词数(英文单词)，以空格或换行为单位； -m 统计字符数； wc 1.txt 默认显示所有的行数、单词数、字符数。 如下图所示：]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sort</tag>
        <tag>uniq</tag>
        <tag>wc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jmeter中常用的函数和方法]]></title>
    <url>%2F2019%2F02%2F26%2F%E4%B8%80%E4%BA%9B%E6%9C%89%E7%94%A8%E7%9A%84%E5%87%BD%E6%95%B0%E5%92%8C%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1、获取当前线程的名称ctx.getThread().getThreadName() 有两种方法，可以直接用一个函数： ${__BeanShell(ctx.getThread().getThreadName().toString(),)} 也可以在beanshell里写脚本：1234import org.apache.jmeter.util.JMeterUtils; String threadinfo = ctx.getThread().getThreadName().toString();log.info(&quot;threadinfo---&quot;+threadinfo); 2、保存变量到文件中下面以保存 cookies 为例，其它变量是类似的.1234567891011import java.lang.String;import java.io.*; String str = &quot;$&#123;COOKIE_xxx&#125;,$&#123;COOKIE_xxx&#125;\r\n&quot;; //拼接cookie字符串log.info(&quot;cookieStr: &quot; + str);FileWriter writer = null;writer = new FileWriter(&quot;cookies.csv&quot;, true); //若文件不存在则创建，若文件存在则追加writer.write(str);writer.close();//log.info(&quot;save cookie in file success!&quot;); 3、保存变量到全局属性中12# props.put() 保存变量到属性中,如:props.put(&quot;access_token&quot;,&quot;$&#123;access_token&#125;&quot;); 4、获取属性值12345# props.get() 从属性中取出变量值:String access_token = props.get(&quot;access_token&quot;);# &quot;$&#123;__P()&#125;&quot; 从属性中取出变量值:$&#123;__P(access_token,)&#125; 以上两种方式都可以从属性中取出 access_token 的值。 5、使用 CookieManager 自定义 cookie 信息jmeter 中可以用 cookie 管理器来添加 cookie 信息； 也可以通过 beanshell 脚本，使用 CookieManager 自定义 cookie 信息。 示例如下：12345678910111213import org.apache.jmeter.protocol.http.control.CookieManager;import org.apache.jmeter.protocol.http.control.Cookie; CookieManager manager = sampler.getCookieManager();String s=&quot;\&quot;&quot;+&quot;$&#123;COOKIE_user_id&#125;&quot;+&quot;\&quot;&quot;;log.info(&quot;s---&quot;+s);Cookie cookie = new Cookie(&quot;user_id&quot;,s,&quot;$&#123;ip&#125;&quot;,&quot;/&quot;,false,0);manager.add(cookie);Cookie cookie = new Cookie(&quot;app_id&quot;,&quot;$&#123;app_id&#125;&quot;,&quot;$&#123;ip&#125;&quot;,&quot;/&quot;,false,0);manager.add(cookie);]]></content>
      <categories>
        <category>jmeter</category>
      </categories>
      <tags>
        <tag>jmeter</tag>
        <tag>jmeter函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不同操作系统中的换行符]]></title>
    <url>%2F2019%2F02%2F26%2F%E4%B8%8D%E5%90%8C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E6%8D%A2%E8%A1%8C%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[一、不同操作系统下换行符的显示换行符在 Windows 和 Linux 等系统中的显示符号是不一样的。 操作系统 换行符 Windows \r\n，回车加换行 类 Unix \n，换行 Mac \r，回车 \r 表示回车，即 CR （carriage return） \n 表示换行，即 LF （linefeed） 二、关于不同换行符的来历1、回车和换行计算机还没有出现之前，使用的是电传打字机来打字（就是上一篇文章中提到的 Teletypewriter）。 电传打字机每秒钟可以打10个字符。但是它有一个问题，就是打完一行换行的时候要用掉0.2秒，正好可以打两个字符。 如果在这0.2秒里面，又有新的字符传过来，那么这个字符将会丢失。 于是科学家想了个办法解决这个问题，就是在每行后面加两个表示结束的字符，回车和换行： 回车，符号 \r；是告诉打字机把打印头定位在左边界； 换行，符号 \n；是告诉打字机把纸张向下方移动一行； 这就是 回车和 换行 的来历。 2、不同系统下的实现方式后来，计算机发明了，回车和换行的概念就被用到了计算机上。当时存储器很贵，一些科学家认为在每行结尾加两个字符太浪费空间了，于是，就出现了分歧。 类 Unix 系统里，每行结尾只有“&lt;换行&gt;”，即“\n”； Windows系统里面，每行结尾是“&lt;回车&gt;&lt;换行&gt;”，即“ \r\n”； Mac系统里，每行结尾是“&lt;回车&gt;”，即“\r”。 在类 Unix 系统中，遇到换行符 \n，就会自动加上\r实现 回车+换行 的操作； 在 Mac 系统中，遇到回车符 \r，就会自动加上\n实现 回车+换行 的操作； 所以，在打开其它系统的文件时，有可能不会正常显示换行。 3、可能会出现的问题因为换行符的问题，在一个系统下编辑的文件放到另一个系统下时，可能会显示不正常。 常见的会有以下两种情况： 在类 Unix 系统或 Mac 系统中编辑的文件，在 Windows 记事本中多行文字会变成一行（但是有些智能编辑器会自动识别不同系统的换行符，并进行转换，如 UE、Notepad++）。 在 Windows 记事本中编辑的文件，在其它系统中会多显示一个控制字符 ^M（在 Linux 中，回车符 \r会作为控制字符 ^M显示）。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>换行符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用du、df和sort命令快速找出linux系统中的大文件]]></title>
    <url>%2F2019%2F02%2F26%2F%E4%BD%BF%E7%94%A8du%E3%80%81df%E5%92%8Csort%E5%91%BD%E4%BB%A4%E5%BF%AB%E9%80%9F%E6%89%BE%E5%87%BAlinux%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%A4%A7%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在性能测试中，我们经常要关注系统磁盘空间，防止因磁盘空间占满而导致的报错，那么具体怎么查看磁盘空间的大小呢？怎么找到占用空间最大的文件呢？ 使用df、du并结合sort，可以快速找到系统中的大文件！ 一、df 和 du 两者区别1、df—disk free 可以快速获取 磁盘 被占用了多少空间，目前还剩下多少空间等信息。 2、du—disk usage 显示磁盘空间的使用情况，统计 目录（或文件）所占磁盘空间的大小。 是不是感觉字面看起来没啥区别呀？哈哈，实际有很多不同哦 3、df 和 du 的不同点：（1）统计的范围不同123df 是从总体上统计系统各磁盘的占用情况，不能统计具体的文件夹或文件的大小。du 既可以从总体上统计，又可以统计具体的某个文件夹或文件的大小。 （2）计算方式不同，计算速度不同1234df 通过文件系统来快速获取空间大小的信息，速度快，效率高du 通过逐级进入指定目录的每一个子目录，逐个计算每个文件大小并相加，最终显示出来。所以计算速度慢，当文件目录较多文件较大时要等很久很久！！而且因为要进入每个子目录计算文件大小，如果当前用户对某些文件/夹没有访问权限时，无法进行计算。 （3）计算结果的差异1234567df 可以获取已经删除的文件。由于df是通过文件系统来获取空间大小的，当我们删除一个文件的时候，这个文件不是马上就在文件系统当中消失了，而是暂时消失了，当所有程序都不用时，才会根据OS的规则释放掉已经删除的文件。所以当一个文件刚删除清空没完全释放时，df 仍会把它计算在内。（当你删除一个大文件前后可以分别用df 命令查看一下，刚删除时还在占用磁盘空间）du 只能看到当前存在的、没有被删除的文件。他计算的大小就是当前他认为存在的所有文件大小的累加和。当文件系统也确定删除了该文件后，这时候du与df 的结果就一致了。所以在这一点上，可以说du 计算更精确，也可以说df 计算有延迟，根据个人情况使用就行。 二、df 命令1、df -h(-h参数使结果以K，M，G为单位，提高信息的可读性) 1234[app@VM_18_18_centos jjingli]$ df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 20G 15G 4.3G 78% //dev/vdb 118G 100G 13G 89% /data 默认显示系统所有的磁盘情况，此图中显示当前一共有两个硬盘分区，及各自的占用情况。 2、df -h 分区名该命令可以指定显示某个分区的占用情况，用的比较少 当使用 df -h 命令看到磁盘占用较高时，需要使用 du 命令进一步查看哪些文件较大，进而删除。 三、du 命令1、du -sh(-h 参数同样是为了提高可读性，-s 代表summary，只显示总大小) 12[app@VM_18_18_centos jjingli]$ du -sh6.4G 默认显示当前目录下所有文件和文件夹的总大小。 当目录下文件夹特别多时，记得不要去掉-s参数，不然会把所有文件夹下的所有文件分别列出来。 2、du -sh 目录名du -sh 在不指定目录的情况下，默认会显示当前目录下的所有子目录的总大小。 du -sh 目录名 在指定目录的情况下，会显示指定目录下的所有文件或文件夹的大小。12345du -sh * # 显示当前目录下的所有文件和文件夹大小du -sh / # 显示根目录下所有的文件和文件夹大小du -sh /data # 显示/data目录下所有的文件和文件夹大小 3、du 和 sort 结合对文件排序1234567891011121314# 查看/data目录下的所有文件和文件夹大小，并从大到小排序du -sh /data | sort -nr这个命令对吗？不对！因为du -sh展示的结果单位不同，但是sort排序只能针对数字，导致980KB的文件排在1GB文件的前面。 # 查看/data目录下的所有文件和文件夹大小，找出所有GB大小的文件，并从大到小排序du -sh /data | grep G | sort -nr# 这样就可以达到目的了~, 但是如果文件夹较多的话，还要一个一个的进入去找# 去掉 -s 参数，可以直接查看包括所有文件夹下的所有文件du -h /data | grep G | sort -nr]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sort</tag>
        <tag>du</tag>
        <tag>df</tag>
        <tag>linux大文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux定时任务crontab]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1crontab%2F</url>
    <content type="text"><![CDATA[在Linux或类Unix系统中，通常使用 crontab 命令在指定的时间执行一个shell脚本或者一系列Linux命令，也就是通常所说的定时任务。 一、cron 进程在详细介绍crontab之前，必须要说一下 cron 进程。 1、cron进程是linux中的守护进程，在系统后台运行，它会（默认每分钟）持续地检查/etc/crontab文件、/etc/cron.*/目录、/var/spool/cron/ 目录，读取调度任务并执行。 2、所有用户创建的crontab文件都保存在/var/spool/cron/ 目录，被cron服务定时检查。 二、crontab命令crontab 命令可以用来创建、编辑、查询、删除定时任务。 通过 crontab 命令，每个用户都可以编辑或者配置自己的定时任务，并拥有自己的 crontab 文件。 ##1、创建/编辑 crontab 文件 在 linux 命令行中输入crontab -e, 即可创建或编辑用户自己的crontab文件： crontab -e 当crontab文件不存在时，即为创建；已存在时即为编辑； 此时，可以输入具体的crontab命令，用来增加、修改或删除当前用户的某一项任务。 在crontab文件中，每一行命令代表一个定时任务！ 2、crontab 语法（字段介绍）此时，即可输入crontab命令，具体语法如下： 1 2 3 4 5 /path/to/command arg1 arg2 或者： 1 2 3 4 5 /root/ntp_sync.sh 各字段的格式： {minute} {hour} {day-of-month} {month} {day-of-week} {full-path-to-shell-script} 分钟 (0-59) 小时 (0-23) 日期 (1-31) 月份 (1-12) 一周当中的某天 (0-7 [7 或 0 代表星期天]) 计划执行的脚本或命令的完整路径 3、crontab 命令示例（结合下一部分的操作符使用方法一起学习）12345678910111213141516171819202122### 每隔 5 分钟运行一次 backupscript 脚本 ##*/5 * * * * /root/backupscript.sh### 每天的凌晨 1 点运行 backupscript 脚本 ##0 1 * * * /root/backupscript.sh### 每月的第一个凌晨 3:15 运行 backupscript 脚本 ##15 3 1 * * /root/backupscript.sh### 每个工作日(Mon – Fri) 11:59 p.m 都进行备份作业。59 23 * * 1,2,3,4,5 /root/bin/backup.sh或者：59 23 * * 1-5 /root/bin/backup.sh### 每周六、周日的3点10分执行hello.sh10 3 * * 0,6 hello.sh### 晚上11点到早上8点之间每两个小时，及每天早上八点，输出信息到文件中0 23-7/2,8 * * * echo &quot;have a good dream：）&quot; &gt;&gt; /tmp/test.txt### 每个月的4号与每个礼拜的礼拜一到礼拜三的早上11点执行命令0 11 4 * 1-3 command 可以把经常要做的一些事放到其中，简化工作量，如每周一检查服务器的运行状态，查看报告，杀掉一些进程等等…… 4、crontab 命令辅操作符操作符允许为一个字段指定多个值，这里有三个操作符可供使用： 星号 (*) : 代表任何时刻 举个例子，在小时字段中，一个星号等同于每个小时；在月份字段中，一个星号则等同于每月。 逗号 (,) : 在一个字段上指定多个值，例如：1,5,10,15,20,25 横杠 (-) : 指定了一个值的范围 例如：5-15 ，等同于使用逗号操作符键入的 5,6,7,8,9,…,13,14,15。 分隔符 (/) : 代表‘每’，/n表示每隔n单位间隔 例如：小时字段为*/5 表示每5小时，也可以写成0-23/5，意思一样。其它字段也是类似的。 5、crontab 查看和删除某用户所有的定时任务123456789crontab -l # 默认查看当前用户的所有定时任务# 使用-u 参数查看指定用户的定时任务，需要以root用户身份执行crontab -u username -l crontab -r # 删除当前用户的crontab的所有任务内容，慎用!### 删除指定用户名下的定时任务，需要以 root 用户身份执行，慎用！crontab -r -u username 6、禁用邮件输出默认情况下，某个命令或者脚本的输出内容（如果有的话）会发送到你的本地邮箱账户中。若想停止接收 crontab 发送的邮件，需要添加 &gt;/dev/null 2&gt;&amp;1 这段内容到执行的命令的后面，例如: 0 3 * * * /root/backup.sh &gt;/dev/null 2&gt;&amp;1 7、使用特殊字符串linux中提供了以下 8 个特殊字符串，可以用来替代crontab命令的前五个字段，这样不但可以节省时间，还可以提高可读性。 特殊字符 含义 @reboot 在每次启动时运行一次 @yearly 每年运行一次, 等同于 “0 0 1 1 *” @annually (同 @yearly) @monthly 每月运行一次, 等同于 “0 0 1 ” @weekly 每周运行一次, 等同于 “0 0 0” @daily 每天运行一次, 等同于 “0 0 *” @midnight (同 @daily) @hourly 每小时运行一次, 等同于 “0 ” 示例： ## 每小时运行一次 ntpdate 命令 @hourly /path/to/ntpdate]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>定时任务</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有道云和csdn中使用markdown]]></title>
    <url>%2F2019%2F02%2F26%2F%E6%9C%89%E9%81%93%E4%BA%91%E5%92%8Ccsdn%E4%B8%ADmarkdown%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[此文中的方法适用于有道云和csdn的markdown编辑器，其它平台尚未验证。 一、字体增大1、为什么要字体增大？有道云的普通笔记可以设置默认字体大小，但是不支持markdown默认字体。当写完预览markdown，发会现，正文字太小了。 2、字体增大的方法？ 用一组 &lt;font size=4&gt; &lt;/font&gt;将全部正文内容包含进去就可以了。 可以直接修改正文中的所有普通文本大小，同时不会影响标题字号。 可以修改size自由调整大小 二、生成目录1、为什么要生成目录？方便有个对文章的大局观，一眼就知道这篇文章到底写了什么，便于定位。 2、生成目录的方法？ 非常简单，直接在第一行加上 [toc]即可！ 当然，前提是你在正文中正确使用了标题格式。 如果在第一行设置了字体大小，那么把 [toc]写在第二行就行了。 三、设置锚点-页内链接1、锚点的作用？ 用于文章快速定位，点击目录便可直接跳转到指定位置。 锚点是是网页制作中超级链接的一种，又叫命名锚记。 使用命名锚记可以在文档中设置标记，这些标记通常放在文档的特定主题处或顶部。然后可以创建到这些命名锚记的链接，这些链接可快速将访问者带到指定位置。 2、如何创建锚点？锚点的添加：使用a标签，href里面填写对应的标题名字 分为两步： 创建命名锚记 格式为 [指引到目标位置的说明文字](#目标位置的id名称) 创建到该命名锚记的链接 格式为 &lt;span id = &quot;目标位置的id名称&quot;&gt;跳转到的目标位置&lt;/span&gt; 举例：123&lt;a href="#jump" target="_self"&gt;说明文字&lt;/a&gt;&lt;span id ="jump"&gt;&lt;font color="red"&gt;跳转到这里：&lt;/font&gt;&lt;/span&gt; 效果： 说明文字 跳转到这里： 四、输入空格有两种方法： 1、中文模式下，Shift+空格切换为全角模式后，按空格键即可。 2、\&nbsp; 或 \&#160; 需要几个空格就输入几次。 五、csdn markdown中添加黄色高亮在有道云笔记的markdown编辑器中，工具栏有Mark按钮可以直接对文字进行黄色高亮显示，非常方便。 实际在源码中是通过一对 == 包围文字即可。 在csdn markdown中也可以用这种方法，实现黄色高亮！ 如： ==xxxxxxx==xxxxx 效果：==xxxxxxx==xxxxx 六、表格内换行使用html代码\实现单元格换行，变相实现合并单元格的效果。 1、markdown语法：1234|姓名|爱好|--|--|张三|足球&lt;br&gt;篮球李四|羽毛球&lt;br&gt;乒乓球 2、实现效果： 姓名 爱好 张三 足球篮球 李四 羽毛球乒乓球]]></content>
      <categories>
        <category>办公利器</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结linux中文本查看命令cat-less-more-tail-head]]></title>
    <url>%2F2019%2F02%2F26%2F%E6%80%BB%E7%BB%93linux%E4%B8%AD%E6%96%87%E6%9C%AC%E6%9F%A5%E7%9C%8B%E5%91%BD%E4%BB%A4cat-less-more-tail-head%2F</url>
    <content type="text"><![CDATA[0、各命令的主要区别：linux命令中cat、more、less、tail、head均可用来查看文件内容，主要区别有： cat是一次性显示整个文件的内容，适用于文件内容少的情况； more和less一般用于显示文件内容超过一屏的内容，并且提供翻页的功能。 tail 和 head分别显示文件的后几行和前几行内容。常用于大文件的截取。 一、catcat 命令常用于显示整个文件的内容，或者合并多个文件。 cat [options] fileName 1、常用参数： -n 或 --number：由 1 开始对所有输出的行数编号。 -b 或 --number-nonblank：和 -n 相似，只不过对于空白行不编号。 2、实例：（1）把 file1 的文档内容全部显示在屏幕上： cat file1 （2）把 file1 的文档内容加上行号后输入 file2 这个文档里： cat -n file1 &gt; file2 （注意：如果file2中原本有内容，此命令会覆盖file2中原有内容） （3）把file1和file2的内容合并到file3，同样会覆盖原file3.txt中的内容： cat file1 file2 &gt; file3 （4）把 file1 和 file2 的文档内容加上行号（空白行不加）之后将内容追加到 file3 文档里： cat -b file1 file2 &gt;&gt; file3 （5）清空 /etc/test.txt 文档内容： cat /dev/null &gt; /etc/test.txt ==当使用&gt;时，cat会覆盖右边的文件；当使用&gt;&gt;时，cat会追加到右边的文件中。== 3、cat 的反命令–tac 命令把cat 单词反过来就是 tac, 该命令同样是显示整个文件的内容，但是倒序显示。 二、moremore 比 cat 功能更强大，会让日志分页显示，同时显示内容的百分比，更方便阅读。 最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能（只能用/向下搜索）。 1、语法：more [-dlfpcsu] [-num] [+/pattern] [+linenum] [fileNames..] 2、常用参数： -num 一次显示的行数 +/pattern 在每个文档显示前搜寻该字串（pattern），然后从该字串前两行开始显示 /字符串：向下搜索”字符串”的功能 +num 从第 num 行开始显示 fileNames 欲显示内容的文档，可以是多个文件 3、实例：（1）逐页显示file1内容： more file1 （2）设定每屏显示的行数： more -10 file1 以10行为单位翻页 （3）从第 20 行开始显示 file1 内容： more +20 file1 （4）同时显示多个文件内容： more file1 file2 依次显示出file1和file2的全部内容。 （5）从文件中查找第一个出现”liu”字符串的行，并从该处前两行开始显示输出： more +/liu test.log 4、常用操作命令 命令 作用 Enter 向下n行，需要定义，默认为1行 空格键 向下滚动一屏 b 向上滚动一屏 = 输出当前行的行号 :f 输出文件名和当前行的行号 V 调用vi编辑器 ! 调用Shell，并执行命令 三、lessless 与 more 类似，less 的用法比起 more 更加的有弹性。 而且拥有更多的搜索功能，不止可以向下搜，也可以向上搜，跟vi中的搜索功能更相似。 1、语法：less [参数] [fileNames...] 2、常用参数： 命令 作用 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -M 显示读取文件的百分比、行号及总行数 -N 在每行前显示行号 /字符串 向下搜索”字符串”的功能 ?字符串 向上搜索”字符串”的功能 n 重复前一个搜索（与 / 或 ? 有关） N 反向重复前一个搜索（与 / 或 ? 有关） &amp;pattern 仅显示匹配模式的行，而不是整个文件 空格键 滚动一页 回车键 滚动一行 [pagedown] 向下翻动一页 [pageup] 向上翻动一页 G 移动到最后一行 g 移动到第一行 v 使用配置的编辑器编辑当前文件 h 显示 less 的帮助文档 3、less 版 tail -f在 Linux 动态查看日志文件常用的命令非 tail -f 莫属。 其实 less 也能完成这项工作，使用 F 命令即可。 在 less 查看日志文件时： 可以按大写 F，就会有类似 tail -f 的效果，读取写入文件的最新内容， 按 ctrl+C 停止。 可以按 v 进入编辑模型， shift+ZZ 保存退出到 less 查看模式。 可以按 :e 查看下一个文件， 用 :n 和 :p 来回切换。 4、实例1、分页查看文件，与more类似： less log1.log 2、ps查看进程信息并通过less分页显示同时显示行号： ps -ef | less -N 3、查看命令历史使用记录并通过less分页显示： 4、浏览多个文件 less log2.log log2.log 说明： 输入 ：n后，切换到 log2.log 输入 ：p 后，切换到log1.log 总结：less 和 more 对比 1、more命令从前向后读取文件，因此在启动时就加载整个文件，如果文件较大时，加载速度慢。 2、 less 并未在一开始就读入整个文件，因此在遇上查看大文件时，会比more、vi等工具的速度更快。同时，less的查找功能更强大。 3、more和less都支持：用空格显示下一页，按键b显示上一页。。 四、tailtail 用来显示文件的最后几行内容。 当文件内容有更新时，tail会自己主动刷新，确保一直显示最新的文件内容。 1、命令语法tail [ -f ] [ -c Number | -n Number | -m Number | -b Number | -k Number ] [ File ] 2、常用参数： -f 监视File文件增长，动态刷新文件 -n Number 从倒数Number行位置读取指定文件 -c Number 从倒数Number字节数位置读取指定文件 3、实例（1）显示文件最后几行内容： tail filename 默认只显示文件最后10行内容，并退出文件，不会自动刷新。 （2）显示文件最后50行内容： tail -n 50 filename 显示文件最后50行内容，并退出文件，不会自动刷新。 （3）显示文件最后内容，并动态刷新： tail -f filename 或 tailf filename 监视filename文件的尾部内容（默认10行，相当于增加参数 -n 10），并动态刷新显示在屏幕上。按下CTRL+C可退出。 （4）指定文件动态刷新的行数：tail -50f filename显示最后50行文件内容，并动态刷新，每次刷新50行。（5）截取文件的后1000行，并保存到新文件中 tail -n 1000 file1.txt &gt; file2.txt 五、headhead 用来显示文件的前面几行内容，可以指定行数和字节数。 1、命令语法tail [-v | -c Number | -n Number] [ File ] 2、常用参数： -v 在输出内容前面显示文件名 -n Number 显示文件的前面Number行内容 -c Number 显示文件的前面Number字节内容 3、实例（1）显示前5行，并显示文件名 head -vn 5 head.txt （2）显示前5个字节 head -c 5 head.txt （3）截取文件的前100行，并保存到新文件中 head -n 1000 file1.txt &gt; file2.txt 总结：tail 和 head 对比1、tail 可显示文件最后几行的内容，并动态刷新。 2、head 可显示文件前面几行的内容。 3、二者也常用于大文件的截取。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cat</tag>
        <tag>less</tag>
        <tag>more</tag>
        <tag>tail</tag>
        <tag>head</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看图学Git！]]></title>
    <url>%2F2019%2F02%2F26%2F%E7%9C%8B%E5%9B%BE%E5%AD%A6Git%20!%2F</url>
    <content type="text"><![CDATA[之前在学习 git 的过程中，经常被各种命令和概念搞晕，所以我总结了一个个图表，方便记忆，希望对正在学习git 的朋友有帮助。 能发图就不打字，哈哈哈哈哈…… 一、常用命令图解单纯用文字表达不容易理解，所以我把关键内容转化成图表，方便理解。 1、add - commit - push 2、暂存区-本地仓库-远程仓库可以结合上面的图一起理解。(这张图是借鉴其它网友的，不记得在哪里看的了) 二、主要功能图解我把 git 的主要功能全部体现在这张图里了，一图在手，git 无忧~ 如果还觉得不够详细，再放出我之前总结的思维导图吧：]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能测试脚本参数化的思考]]></title>
    <url>%2F2019%2F02%2F26%2F%E8%84%9A%E6%9C%AC%E5%8F%82%E6%95%B0%E5%8C%96%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[一、脚本参数化简单的说，脚本参数化实际就是用参数来替换脚本中的一些常量，把常量替换成变量，把脚本与数据进行分离。 二、为什么要进行参数化？对测试脚本参数化，主要有两种目的。 1、为了保证请求被正常处理如注册场景必须要求用户名不重复等 2、为了模拟真实的生产场景如在登录场景中使用多用户，而不是单用户，防止出现因频率限制导致的报错，防止因命中缓存导致的TPS过高的假象。 通常很多系统出于性能优化考量，针对各业务场景都会大量使用到缓存，导致压测数据相同时，每次命中缓存后快速响应请求，造成站点压测性能极佳的假象（但线上真实请求参数各异）。 所以在做压测时，为了满足模拟真实压测环境要求，就需要让每个压测请求都携带不同的线上请求参数。 三、如何模拟真实稳定的压测环境？具体在开发脚本时，怎么做到模拟真实的生产环境呢？ 需要做如下准备： 准备压测数据 让每个压测线程，每次访问目标服务器时，分别携带不同的请求参数 控制单个压测线程的单次执行时间，保证各线程能以稳定速率向目标服务器发送请求 脚本是否能通过传参灵活控制内部逻辑]]></content>
      <categories>
        <category>jmeter</category>
      </categories>
      <tags>
        <tag>参数化</tag>
        <tag>性能测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven入门学习01-关键特性]]></title>
    <url>%2F2019%2F02%2F26%2Fmaven%E5%AD%A6%E4%B9%A001%20-%20%E5%85%B3%E9%94%AE%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[一、认识 Maven1、Maven 最重要的功能Apache Maven 是一个强大的项目管理工具，可以用于项目构建、依赖管理、项目信息管理。 Maven 更多的被用作项目构建工具，它使项目的构建过程简单化、标准化、可复用，极大的方便了整个项目的开发和管理。 它基于工程对象模型（POM）的概念，使用 pom.xml进行核心功能配置，进而管理项目的构建、报告和文档等。 2、什么是构建工具？构建工具是将软件项目构建相关的过程自动化的工具。 构建一个软件项目通常包含以下一个或多个过程： 生成源码（如果项目使用自动生成源码）； 从源码生成项目文档； 编译源码； 将编译后的代码打包成JAR文件或者ZIP文件； 将打包好的代码安装到服务器、仓库或者其它的地方； 当然，有些项目可能需要更多的过程才能完成构建，同样也可以实现自动化。 自动化构建过程的好处： 将手动构建过程中犯错的风险降到最低。 自动构建工具通常要比手动执行同样的构建过程要快。 二、Maven 关键特性1、简化并标准化项目构建过程 Maven 为开发者提供了一套完整的构建生命周期框架，开发人员只需要按照框架操作。 Maven 使用一个标准的目录结构和一个默认的构建生命周期，开发人员只需要把代码放入相应的目录中并使用默认配置。 2、自动管理依赖2.1 以前项目开发中的问题jar 包依赖和冲突问题： 在构建一个大型项目时，经常需要用到很多第三方的类库，需要引入大量的jar包，需要一个个去查找。 一个大型项目中 jar 包的数量之多往往让我们瞠目结舌，并且jar包之间的关系错综复杂，多个jar包之间又可能会引起冲突问题，都可能导致项目编译失败。 以往开发项目时，程序员往往需要花较多的精力在引用jar包搭建项目环境上，而这一项工作尤为艰难，少一个Jar包、多一个jar包往往会报一些让人摸不着头脑的异常。 2.2 Maven 如何解决依赖问题？我们只需要告诉Maven需要哪些 jar 包，它会帮助我们自动下载、并统一管理，极大提升开发效率。 自动下载依赖jar包 通过在pom.xml文件中的&lt;dependency&gt;节点添加相应配置，就会自动下载相应jar包。123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; 项目名 &lt;artifactId&gt;junit&lt;/artifactId&gt; 项目模块 &lt;version&gt;4.1.1&lt;/version&gt; 项目版本 &lt;scope&gt;test&lt;/scope&gt; 作用范围 &lt;/dependency&gt; 自动管理依赖 每一个jar包也有自己的 pom.xml文件，里面也会有&lt;dependency&gt;配置，在这里配置的是这个jar包所依赖的其他jar包，也会被maven自动下载下来 统一管理jar包 通过仓库来实现统一管理，后面会详细讲解Maven仓库的概念。 3、约定优于配置Maven 使用约定而不是配置。 也就是说开发者不需要关心每一个配置细节，Maven 会为工程提供合理的默认行为。 当创建 Maven 工程时，Maven 会创建默认的工程结构。开发者只需要合理的放置文件，不再需要定义任何配置。 下表是工程源码文件、资源文件的默认配置，和其他一些配置： （假定 ${basedir} 表示工程目录） 配置项 默认值 source code ${basedir}/src/main/java resources ${basedir}/src/main/resources Tests ${basedir}/src/test Complied byte code ${basedir}/target distributable JAR ${basedir}/target/classes 4、热部署，热编译在web项目已经运行的时候，修改代码能直接被web服务器所接受，不需要重启服务器或者重新部署代码，而且可以直接通过maven 打包war或者jar项目。]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>mavne关键特性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[总结linux中文件查找命令find-locate-whereis-which]]></title>
    <url>%2F2019%2F02%2F26%2F%E6%80%BB%E7%BB%93linux%E4%B8%AD%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%91%BD%E4%BB%A4find-locate-whereis-which%2F</url>
    <content type="text"><![CDATA[0、各命令的主要区别：linux命令中find、locate 、whereis、which均可用来查找文件，主要区别有： find是最常用和最强大的查找命令。它能做到实时查找，精确查找，但查找内容较多时速度慢； locate查找速度快，但是不是实时查找，所以查找的结果不精确； whereis用于查找二进制文件、源代码文件和man手册页； which指令会在环境变量$PATH设置的目录里查找符合条件的文件。 一、find 查找文件 find命令用来在指定目录下查找文件。 任何位于参数之前的字符串都将被视为欲查找的目录名。 ==如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。== 1、语法find path -option [ -print ] [ -exec -ok command ] {} \; 2、参数说明find 根据下列规则判断 path 和 expression： 在命令列上第一个 - ( ) , ! 之前的部份为 path，之后的是 expression。 如果 path 是空字串则使用目前路径 如果 expression 是空字串则使用 -print 为预设 expression。（expression 中可使用的选项有二三十个之多，在此只介绍最常用的部份。） 参数 说明 -cmin n 在过去 n 分钟内被修改过 -ctime n 在过去n天内被修改过的文件 -mtime n 在过去 n 天内被修改过-（跟上面两个选项的区别见下面） -mmin n 在过去 n 天内被修改过-（跟上面两个选项的区别见下面） -empty 空的文件，寻找文件大小为0 Byte的文件，或目录下没有任何子目录或文件的空目录； -ipath p, -path p 匹配文件路径，ipath 会忽略路径大小写 -name name, -iname name 匹配文件名称。iname 会忽略名称大小写 -size n 匹配文件大小，单位有：c–字节，k–千字节，M–兆字节，G– -type c 匹配文件类型，c是指定的类型。文件类型参数有：f–普通文件，d–目录，l–符号链接 -exec&lt;执行指令&gt; 假设find指令的回传值为True，就执行该指令； -ok&lt;执行指令&gt; 此参数的效果和指定“-exec”类似，但在执行指令之前会先询问用户，若回答“y”或“Y”，则放弃执行命令； -regex&lt;范本样式&gt; 指定字符串作为寻找文件或目录的范本样式； 3、UNIX/Linux文件系统时间戳UNIX/Linux文件系统中，每个文件都有三种时间戳： 时间戳 说明 访问时间（-atime/天，-amin/分钟） 用户最近一次访问时间。 修改时间（-mtime/天，-mmin/分钟） 文件最后一次修改时间。 变化时间（-ctime/天，-cmin/分钟） 文件数据元（例如权限等）最后一次修改时间。 另外，还可以使用 ( ) 将运算式分隔，并使用下列运算：12345exp1 -and exp2! expr-not exprexp1 -or exp2exp1, exp2 4、实例（1）匹配文件名称12345678将当前目录及其子目录下所有.py后缀的文件列出来：find . -name &quot;*.py&quot;find . -iname &quot;*.py&quot; （同上，但忽略大小写，.PY后缀的文件也列出来）当前目录及子目录下查找所有以.txt和.pdf结尾的文件：find . \( -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; \)或find . -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; （2）匹配文件路径123456789匹配文件路径或者文件：find /usr/ -path &quot;*local*&quot;基于正则表达式匹配文件路径：find . -regex &quot;.*\(\.txt\|\.pdf\)$&quot;（查找当前目录及子目录下所有以.txt或.pdf结尾的文件）同上，但忽略大小写：find . -iregex &quot;.*\(\.txt\|\.pdf\)$&quot; （3）否定参数 ！12找出/home下不是以.txt结尾的文件：find /home ! -name &quot;*.txt&quot; （4）匹配文件类型12将当前目录及其子目录中所有的一般文件列出：find . -type f （5）匹配文件时间戳1234567891011搜索最近七天内被 访问 过的所有文件：find . -type f -atime -7搜索恰好在七天前被 修改 过的所有文件：find . -type f -mtime 7搜索超过七天内被 修改 过的所有文件：find . -type f -mtime +7将目前目录及其子目录下所有最近 20 天内更新过的文件列出：find . -ctime -20 （6）匹配文件大小1234567891011搜索大于10KB的文件：find . -type f -size +10k搜索小于10KB的文件：find . -type f -size -10k搜索等于10KB的文件：find . -type f -size 10k搜索所有长度为零的文件：find . -empty （7）删除匹配文件12删除当前目录下所有.txt文件：find . -type f -name &quot;*.txt&quot; -delete （8）借助-exec选项与其它命令结合使用12345678910111213141516171819202122232425找出当前目录下所有root的文件，并把所有权更改为用户tom：find .-type f -user root -exec chown tom &#123;&#125; \;上例中，&#123;&#125; 用于与-exec选项结合使用来匹配所有文件，然后会被替换为相应的文件名。找出自己家目录下所有的.txt文件并删除：find $HOME/. -name &quot;*.txt&quot; -ok rm &#123;&#125; \;上例中，-ok和-exec行为一样，不过它会给出提示，是否执行相应的操作。查找/var/log目录中更改时间在7日以前的普通文件，并在删除之前询问它们：find /var/log -type f -mtime +7 -ok rm &#123;&#125; \;查找系统中所有文件长度为0的普通文件，并列出它们的完整路径：find / -type f -size 0 -exec ls -l &#123;&#125; \;查找当前目录下所有.txt文件并把他们拼接起来写入到all.txt文件中：find . -type f -name &quot;*.txt&quot; -exec cat &#123;&#125; \;&gt; all.txt将30天前的.log文件移动到old目录中：find . -type f -mtime +30 -name &quot;*.log&quot; -exec cp &#123;&#125; old \;找出当前目录下所有.txt文件并以“File:文件名”的形式打印出来：find . -type f -name &quot;*.txt&quot; -exec printf &quot;File: %s\n&quot; &#123;&#125; \;因为单行命令中-exec参数中无法使用多个命令，以下方法可以实现在-exec之后接受多条命令：-exec ./text.sh &#123;&#125; \; 二、locate 查找文件1、locate和find的区别 locate命令也可以用于查找符合条件的文档或目录，但是速度比find快很多。 locate查找命令简单，但功能也较少。 locate 实际上查的是一个保存文档和目录名称的数据库，默认是/var/lib/slocate/slocate.db。 find是去硬盘找，而locate这个数据库里找。 locate的查找并不是实时的，而是以数据库的更新为准。 Linux系统自动创建locate查找的数据库，并且每天自动更新一次。 因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库（也可以使用locate -u命令来更新）。 2、locate命令直接locate fileName 即可查找指定文件，默认支持正则匹配。12345查找出以passwd开头的所有文件locate passwd查找出/data/jjing/目录下所有以test开头的文件或文件夹下的所有内容locate /data/jjing/test 三、whereis和which的对比直接看几个实例吧：12345678910111213141516171819[app@VM_98_10_centos test]$ whereis mysqlmysql: /usr/bin/mysql /usr/lib64/mysql /usr/include/mysql /usr/share/mysql /usr/share/man/man1/mysql.1.gz[app@VM_98_18_centos test]$ which mysql/usr/bin/mysql[app@VM_98_18_centos test]$ whereis pythonpython: /usr/bin/python /usr/bin/python2.6 /usr/bin/python2.6-config /usr/lib/python2.6 /usr/lib64/python2.6 /usr/include/python2.6 /usr/share/man/man1/python.1.gz[app@VM_98_18_centos test]$ which python/usr/bin/python[app@VM_98_18_centos test]$ whereis jenkinsjenkins:[app@VM_98_18_centos test]$ which jenkins/usr/bin/which: no jenkins in (/home/app/bin:/home/app/bin:/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/nemo/jdk8/bin:/nemo/gradle/bin:/home/app/bin:/nemo/jdk1.8.0_141/bin:/usr/local/python3.6.5/bin:/nemo/maven/bin)[app@VM_98_18_centos test]$ whereis vimvim: /usr/bin/vim /usr/share/vim /usr/share/man/man1/vim.1.gz[app@VM_98_18_centos test]$ which vim/usr/bin/vim whereis一般用于查找系统的可执行命令的位置，以及相关的源码文件，及对应的man手册页； which也可以查找可执行命令的位置，但是只在环境变量$PATH设置的目录里查找]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>find</tag>
        <tag>locate</tag>
        <tag>whereis</tag>
        <tag>which</tag>
      </tags>
  </entry>
</search>
